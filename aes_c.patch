diff --git a/library/aes.c b/library/aes.c
index b1a5c3ed1..b57cbec8c 100644
--- a/library/aes.c
+++ b/library/aes.c
@@ -17,6 +17,17 @@
 
 #include <string.h>
 
+#define MBEDTLS_AES_MASKING
+
+#if defined(MBEDTLS_AES_MASKING)
+#include "mbedtls/entropy.h"
+#include "mbedtls/ctr_drbg.h"
+
+static mbedtls_entropy_context entropy_ctx;
+static mbedtls_ctr_drbg_context drbg_ctx;
+static int rng_is_initialized = 0;
+#endif /* MBEDTLS_AES_MASKING */
+
 #include "mbedtls/aes.h"
 #include "mbedtls/platform.h"
 #include "mbedtls/platform_util.h"
@@ -569,6 +580,240 @@ MBEDTLS_MAYBE_UNUSED static unsigned mbedtls_aes_rk_offset(uint32_t *buf)
     return 0;
 }
 
+#if defined(MBEDTLS_AES_MASKING)
+/**
+ * @brief RNG context initialization
+ */
+static int rng_init(void){
+    if (rng_is_initialized) {
+        return 0;
+    }
+
+    mbedtls_entropy_init(&entropy_ctx);
+    mbedtls_ctr_drbg_init(&drbg_ctx);
+
+    const char *seed_str = "aes-masking-test";
+
+    int ret = mbedtls_ctr_drbg_seed(&drbg_ctx, mbedtls_entropy_func, &entropy_ctx,
+                                    (const unsigned char *)seed_str,
+                                    strlen(seed_str));
+
+    if (ret != 0) {
+        return ret;
+    }
+
+    rng_is_initialized = 1;
+    return 0;
+}
+
+/*
+ * Masked SubWord implementation for key expansion
+ * Performs masked operation on a 32-bit word
+ */
+static int masked_subword(uint32_t input_masked, uint32_t input_mask,
+                          uint32_t* output_masked, uint32_t* output_mask)
+{
+    uint32_t fresh_masks;
+
+    int ret = mbedtls_ctr_drbg_random(&drbg_ctx, (unsigned char *)&fresh_masks, 4);
+    if (ret != 0) {
+        return( ret );
+    }
+
+    volatile uint32_t demasked_input = input_masked ^ input_mask;
+    uint32_t sbox_result_masked = 0;
+
+    for(unsigned int i = 0; i < 4; i++){
+        uint8_t temp_demasked_byte = (demasked_input >> (i*8)) & 0xFF;
+        uint8_t temp_mask_out = (fresh_masks >> (i*8)) & 0xFF;
+
+        // Secure SBox lookup - using ad-hoc remasked table
+        uint8_t T[256];
+        for(int j = 0; j < 256; j++) {
+            T[j] = FSb[j] ^ temp_mask_out;
+        }
+        uint8_t res_masked_byte = T[temp_demasked_byte];
+
+        sbox_result_masked |= ((uint32_t)res_masked_byte << (i*8));
+    }
+
+    *output_masked = sbox_result_masked;
+    *output_mask = fresh_masks;
+
+    return(0);
+}
+
+static void masked_shift_rows(
+    uint8_t state_masked[4][4],
+    uint8_t state_mask[4][4])
+{
+    uint8_t temp_m, temp_s;
+
+    // --- Row 1: Cyclically shift left by 1 position ---
+    // Save the first byte
+    temp_m = state_masked[1][0];
+    temp_s = state_mask[1][0];
+    // Shift bytes left
+    state_masked[1][0] = state_masked[1][1];
+    state_mask[1][0]   = state_mask[1][1];
+    state_masked[1][1] = state_masked[1][2];
+    state_mask[1][1]   = state_mask[1][2];
+    state_masked[1][2] = state_masked[1][3];
+    state_mask[1][2]   = state_mask[1][3];
+    // Wrap around
+    state_masked[1][3] = temp_m;
+    state_mask[1][3]   = temp_s;
+
+    // --- Row 2: Cyclically shift left by 2 positions (swap elements) ---
+    // Swap [2][0] with [2][2]
+    temp_m = state_masked[2][0];
+    temp_s = state_mask[2][0];
+    state_masked[2][0] = state_masked[2][2];
+    state_mask[2][0]   = state_mask[2][2];
+    state_masked[2][2] = temp_m;
+    state_mask[2][2]   = temp_s;
+    // Swap [2][1] with [2][3]
+    temp_m = state_masked[2][1];
+    temp_s = state_mask[2][1];
+    state_masked[2][1] = state_masked[2][3];
+    state_mask[2][1]   = state_mask[2][3];
+    state_masked[2][3] = temp_m;
+    state_mask[2][3]   = temp_s;
+
+    // --- Row 3: Cyclically shift left by 3 positions (or right by 1) ---
+    // Save the last byte
+    temp_m = state_masked[3][3];
+    temp_s = state_mask[3][3];
+    // Shift bytes right
+    state_masked[3][3] = state_masked[3][2];
+    state_mask[3][3]   = state_mask[3][2];
+    state_masked[3][2] = state_masked[3][1];
+    state_mask[3][2]   = state_mask[3][1];
+    state_masked[3][1] = state_masked[3][0];
+    state_mask[3][1]   = state_mask[3][0];
+    // Wrap around
+    state_masked[3][0] = temp_m;
+    state_mask[3][0]   = temp_s;
+}
+
+#define XTIME(x) (((x) << 1) ^ (((x) & 0x80) ? 0x1B : 0x00))
+/**
+ * Apply MixColumns operation on masked values and mask independently. This is possible due to linearity of MixColumns operation.
+ */
+static void masked_mix_columns(uint8_t state_masked[4][4], uint8_t state_mask[4][4]){
+    uint8_t c;
+
+    // Masked data share
+    uint8_t a_m, b_m, c_m, d_m;
+    // Mask share
+    uint8_t a_s, b_s, c_s, d_s;
+
+    for(c = 0; c < 4; c++){
+        a_m = state_masked[0][c];
+        b_m = state_masked[1][c];
+        c_m = state_masked[2][c];
+        d_m = state_masked[3][c];
+
+        a_s = state_mask[0][c];
+        b_s = state_mask[1][c];
+        c_s = state_mask[2][c];
+        d_s = state_mask[3][c];
+
+        uint8_t t_m = a_m ^ b_m ^ c_m ^ d_m;
+        uint8_t Tmp_m;
+        /**
+         * Addition in GF(2^8) is XOR
+         * Multiplication in GF(2^8) is:
+         *  - by 1: no-op
+         *  - by 2: left shift with conditional XOR (XTIME)
+         *  - by 3: can be split (3 = 2 ⊕ 1)
+         * 
+         * | 2 3 1 1 |   |a_m|   | 2 * a_m ⊕ 3 * b_m ⊕ c_m ⊕ d_m |   | 2(a_m ⊕ b_m) ⊕ b_m ⊕ c_m ⊕ d_m |
+         * | 1 2 3 1 | x |b_m| = | a_m ⊕ 2 * b_m ⊕ 3 * c_m ⊕ d_m | = | 2(b_m ⊕ c_m) ⊕ a_m ⊕ c_m ⊕ d_m |
+         * | 1 1 2 3 |   |c_m|   | a_m ⊕ b_m ⊕ 2 * c_m ⊕ 3 * d_m |   | 2(c_m ⊕ d_m) ⊕ a_m ⊕ b_m ⊕ d_m |
+         * | 3 1 1 2 |   |d_m|   | 3 * a_m ⊕ b_m ⊕ c_m ⊕ 2 * d_m |   | 2(a_m ⊕ d_m) ⊕ a_m ⊕ b_m ⊕ c_m |
+         * 
+         * 
+         */
+        Tmp_m = a_m ^ b_m; Tmp_m = XTIME(Tmp_m); state_masked[0][c] ^= Tmp_m ^ t_m;
+        Tmp_m = b_m ^ c_m; Tmp_m = XTIME(Tmp_m); state_masked[1][c] ^= Tmp_m ^ t_m;
+        Tmp_m = c_m ^ d_m; Tmp_m = XTIME(Tmp_m); state_masked[2][c] ^= Tmp_m ^ t_m;
+        Tmp_m = d_m ^ a_m; Tmp_m = XTIME(Tmp_m); state_masked[3][c] ^= Tmp_m ^ t_m;
+
+        uint8_t t_s = a_s ^ b_s ^ c_s ^ d_s;
+        uint8_t Tmp_s;
+        Tmp_s = a_s ^ b_s; Tmp_s = XTIME(Tmp_s); state_mask[0][c] ^= Tmp_s ^ t_s;
+        Tmp_s = b_s ^ c_s; Tmp_s = XTIME(Tmp_s); state_mask[1][c] ^= Tmp_s ^ t_s;
+        Tmp_s = c_s ^ d_s; Tmp_s = XTIME(Tmp_s); state_mask[2][c] ^= Tmp_s ^ t_s;
+        Tmp_s = d_s ^ a_s; Tmp_s = XTIME(Tmp_s); state_mask[3][c] ^= Tmp_s ^ t_s;
+    }
+}
+
+int mbedtls_aes_setkey_enc_masked(mbedtls_aes_context *ctx, const unsigned char *key,
+                           unsigned int keybits)
+{
+    if(rng_init()){
+        return -1;
+    }
+
+    if (keybits != 128) {
+        return (MBEDTLS_ERR_AES_INVALID_KEY_LENGTH);
+    }
+
+    ctx->nr = 10;
+
+    uint32_t *RK_masked = ctx->buf_masked;
+    uint32_t *RK_mask = ctx->buf_mask;
+
+    // First 4 words are the same as the original (masked) key
+    for (unsigned int i = 0; i < 4; i++) {
+        uint32_t original_word = MBEDTLS_GET_UINT32_LE(key, i << 2);
+
+         mbedtls_ctr_drbg_random(&drbg_ctx, (unsigned char *)&RK_mask[i], 4);
+         RK_masked[i] = original_word ^ RK_mask[i];
+    }
+
+    // Input window pointers: covering the 4 word long windows of data
+    uint32_t *rk_m = RK_masked;
+    uint32_t *rk_s = RK_mask;
+
+    // Expand the key
+    for (unsigned int i = 0; i < 10; i++, rk_m += 4, rk_s += 4){
+
+        // RK[i] = RK[i-4] ^ SubWord(RotWord(RK[i-1])) ^ RCON
+
+        // RotWord (on masked values)
+        uint32_t temp_rot_masked = (rk_m[3] << 8) | rk_m[3] >> 24;
+        uint32_t temp_rot_mask = (rk_s[3] << 8) | rk_s[3] >> 24;
+    
+        // SubWord (on masked values)
+        uint32_t temp_sub_masked, temp_sub_mask;
+        masked_subword(temp_rot_masked, temp_rot_mask, &temp_sub_masked, &temp_sub_mask);
+
+        uint32_t next_word_masked = rk_m[0] ^ temp_sub_masked;
+        uint32_t next_word_mask = rk_m[0] ^ temp_sub_mask;
+
+        next_word_masked ^= round_constants[i];
+
+        // First 4 words are copy of the initial key
+
+        rk_m[4] = next_word_masked;
+        rk_s[4] = next_word_mask;
+
+        rk_m[5] = rk_m[1] ^ rk_m[4];
+        rk_s[5] = rk_s[1] ^ rk_s[4];
+        
+        rk_m[6] = rk_m[2] ^ rk_m[5];
+        rk_s[6] = rk_s[2] ^ rk_s[5];
+
+        rk_m[7] = rk_m[3] ^ rk_m[6];
+        rk_s[7] = rk_s[3] ^ rk_s[6];
+    }
+
+    return 0;
+}
+#endif /* MBEDTLS_AES_MASKING */
+
 /*
  * AES key schedule (encryption)
  */
@@ -597,6 +842,10 @@ int mbedtls_aes_setkey_enc(mbedtls_aes_context *ctx, const unsigned char *key,
     ctx->rk_offset = mbedtls_aes_rk_offset(ctx->buf);
     RK = ctx->buf + ctx->rk_offset;
 
+#if defined(MBEDTLS_AES_MASKING)
+    return mbedtls_aes_setkey_enc_masked(ctx, key, keybits);
+#endif
+
 #if defined(MBEDTLS_AESNI_HAVE_CODE)
     if (mbedtls_aesni_has_support(MBEDTLS_AESNI_AES)) {
         return mbedtls_aesni_setkey_enc((unsigned char *) RK, key, keybits);
@@ -828,6 +1077,7 @@ int mbedtls_aes_xts_setkey_dec(mbedtls_aes_xts_context *ctx,
 }
 #endif /* MBEDTLS_CIPHER_MODE_XTS */
 
+//                 ouputput        input
 #define AES_FROUND(X0, X1, X2, X3, Y0, Y1, Y2, Y3)                 \
     do                                                      \
     {                                                       \
@@ -876,6 +1126,124 @@ int mbedtls_aes_xts_setkey_dec(mbedtls_aes_xts_context *ctx,
                AES_RT3(MBEDTLS_BYTE_3(Y0));     \
     } while (0)
 
+#if defined(MBEDTLS_AES_MASKING)
+static void masked_add_round_key(
+    uint8_t state_masked[4][4],
+    uint8_t state_mask[4][4],
+    const uint32_t* rk_masked_sched,
+    const uint32_t* rk_mask_sched,
+    int round)
+{
+    const uint8_t* key_m = (const uint8_t*)(rk_masked_sched);
+    const uint8_t* key_s = (const uint8_t*)(rk_mask_sched);
+
+    int offset = round * 16;
+
+    for (int c = 0; c < 4; c++){
+        for(int r = 0; r < 4; r++){
+            int state_idx = r + c * 4;
+            state_masked[r][c] ^= key_m[offset + state_idx];
+            state_mask[r][c] ^= key_s[offset + state_idx];
+        }
+    }
+}
+
+static int masked_sub_bytes(
+    uint8_t state_masked[4][4],
+    uint8_t state_mask[4][4],
+    mbedtls_ctr_drbg_context *drbg_ctx)
+{
+    if (drbg_ctx == NULL){
+        return -1;
+    }
+
+    for (int c = 0; c < 4; c++){
+        for(int r = 0; r < 4; r++){
+            uint8_t x_prim = state_masked[r][c];
+            uint8_t m_in = state_mask[r][c];
+
+            uint8_t m_out;
+            int ret = mbedtls_ctr_drbg_random(drbg_ctx, &m_out, 1);
+            if (ret != 0){
+                return ret;
+            }
+
+            volatile uint8_t demasked_byte = x_prim ^ m_in;
+
+            uint8_t T[256];
+            for (int j = 0; j < 256; j++){
+                T[j] = FSb[j] ^ m_out;
+            }
+
+            uint8_t y_prim = T[demasked_byte];
+
+            state_masked[r][c] = y_prim;
+            state_mask[r][c] = m_out;
+        }
+    }
+
+    return 0;
+}
+
+/**
+ * ctx - masked context
+ */
+int mbedtls_internal_aes_encrypt_masked(mbedtls_aes_context *ctx,
+                                 const unsigned char input[16],
+                                 unsigned char output[16])
+{
+    uint8_t state_masked[4][4];
+    uint8_t state_mask[4][4];
+
+    uint8_t initial_mask_bytes[16];
+    mbedtls_ctr_drbg_random(&drbg_ctx, initial_mask_bytes, 16);
+
+    // P' = P ^ M
+    // Masked plaintext = plaintext XOR mask
+    for(int r = 0; r < 4; r++){
+        for(int c = 0; c < 4; c++){
+            state_masked[r][c] = input[r + c*4] ^ initial_mask_bytes[r + c*4];
+            state_mask[r][c] = initial_mask_bytes[r + c*4];
+        }
+    }
+
+    // Initial round key addition
+    masked_add_round_key(state_masked, state_mask, ctx->buf_masked, ctx->buf_mask, 0);
+
+    for (int round = 1; round < ctx->nr; ++round){
+        // SubBytes
+        masked_sub_bytes(state_masked, state_mask, &drbg_ctx);
+
+        // ShiftRows
+        masked_shift_rows(state_masked, state_mask);
+
+        // MixColumns
+        masked_mix_columns(state_masked, state_mask);
+
+        // AddRoundKey
+        masked_add_round_key(state_masked, state_mask, ctx->buf_masked, ctx->buf_mask, round);
+    }
+
+    // Final round
+    masked_sub_bytes(state_masked, state_mask, &drbg_ctx);
+
+    // ShiftRows
+    masked_shift_rows(state_masked, state_mask);
+
+    // AddRoundKey
+    masked_add_round_key(state_masked, state_mask, ctx->buf_masked, ctx->buf_mask, ctx->nr);
+
+    // Unmask the output
+    for (int r = 0; r < 4; r++){
+        for(int c = 0; c < 4; c++){
+            output[r + c*4] = state_masked[r][c] ^ state_mask[r][c];
+        }
+    }
+    
+    return 0;
+}
+#endif /* MBEDTLS_AES_MASKING */
+
 /*
  * AES-ECB block encryption
  */
@@ -887,10 +1255,11 @@ int mbedtls_internal_aes_encrypt(mbedtls_aes_context *ctx,
     int i;
     uint32_t *RK = ctx->buf + ctx->rk_offset;
     struct {
-        uint32_t X[4];
-        uint32_t Y[4];
+        uint32_t X[4];  // 16 bytes
+        uint32_t Y[4];  // 16 bytes
     } t;
 
+    // Initial AddRoundKey step
     t.X[0] = MBEDTLS_GET_UINT32_LE(input,  0); t.X[0] ^= *RK++;
     t.X[1] = MBEDTLS_GET_UINT32_LE(input,  4); t.X[1] ^= *RK++;
     t.X[2] = MBEDTLS_GET_UINT32_LE(input,  8); t.X[2] ^= *RK++;
@@ -1059,7 +1428,12 @@ int mbedtls_aes_crypt_ecb(mbedtls_aes_context *ctx,
     } else
 #endif
     {
+#if defined(MBEDTLS_AES_MASKING)
+
+        return mbedtls_internal_aes_encrypt_masked(ctx, input, output);
+#else    
         return mbedtls_internal_aes_encrypt(ctx, input, output);
+#endif /* MBEDTLS_AES_MASKING */
     }
 #endif /* !MBEDTLS_AES_USE_HARDWARE_ONLY */
 }
