% Format teze zasnovan je na paketu memoir
% http://tug.ctan.org/macros/latex/contrib/memoir/memman.pdf ili
% http://texdoc.net/texmf-dist/doc/latex/memoir/memman.pdf
% 
% Prilikom zadavanja klase memoir, navedenim opcijama se podešava 
% veličina slova (12pt) i jednostrano štampanje (oneside).
% Ove parametre možete menjati samo ako pravite nezvanične verzije
% mastera za privatnu upotrebu (na primer, u b5 varijanti ima smisla 
% smanjiti 
\documentclass[12pt,oneside]{memoir}

% Paket koji definiše sve specifičnosti mastera Matematičkog fakulteta
\usepackage{matfmaster}

% Paketi za algoritme
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amsfonts}

%
% Podrazumevano pismo je ćirilica.
%   Ako koristite pdflatex, a ne xetex, sav latinički tekst na srpskom jeziku
%   treba biti okružen sa \lat{...} ili \begin{latinica}...\end{latinica}.
%
% Opicija [latinica]:
%   ako želite da pišete latiniciom, dodajte opciju "latinica" tj.
%   prethodni paket uključite pomoću: \usepackage[latinica]{matfmaster}.
%   Ako koristite pdflatex, a ne xetex, sav ćirilički tekst treba biti
%   okružen sa \cir{...} ili \begin{cirilica}...\end{cirilica}.
%
% Opcija [biblatex]:
%   ako želite da koristite reference na više jezika i umesto paketa
%   bibtex da koristite BibLaTeX/Biber, dodajte opciju "biblatex" tj.
%   prethodni paket uključite pomoću: \usepackage[biblatex]{matfmaster}
%
% Opcija [b5paper]:
%   ako želite da napravite verziju teze u manjem (b5) formatu, navedite
%   opciju "b5paper", tj. prethodni paket uključite pomoću: 
%   \usepackage[b5paper]{matfmaster}. Tada ima smisla razmisliti o promeni
%   veličine slova (izmenom opcije 12pt na 11pt u \documentclass{memoir}).
%
% Naravno, opcije je moguće kombinovati.
% Npr. \usepackage[b5paper,biblatex]{matfmaster}

% Pomoćni paket koji generiše nasumičan tekst u kojem se javljaju sva slova
% azbuke (nema potrebe koristiti ovo u pravim disertacijama)
\usepackage{pangrami}

% Paket koji obezbeđuje ispravni prikaz ćiriličkih italik slova kada
% se koristi pdflatex. Zakomentarisati ako na sistemu koji koristite ovaj
% paket nije dostupan ili ako ne radi ispravno.
\usepackage{cmsrb}

% Ostali paketi koji se koriste u dokumentu
\usepackage{listings} % listing programskog koda

% Datoteka sa literaturom u BibTex tj. BibLaTeX/Biber formatu
\bib{bibliografija}

% Ime kandidata na srpskom jeziku (u odabranom pismu)
\autor{Александар Врачаревић}
% Naslov teze na srpskom jeziku (u odabranom pismu)
\naslov{Примена метода дубоког учења у нападу на криптографске алгоритме споредним каналима}
% Godina u kojoj je teza predana komisiji
\godina{2025}
% Ime i afilijacija mentora (u odabranom pismu)
\mentor{др Младен \textsc{Николић}, редован професор\\ Универзитет у Београду, Математички факултет}
% Ime i afilijacija prvog člana komisije (u odabranom pismu)
\komisijaA{др Јована \textsc{Ковачевић}, ванредни професор\\ University of Disneyland, Недођија}
% Ime i afilijacija drugog člana komisije (u odabranom pismu)
\komisijaB{др Александар \textsc{Картељ}, доцент\\ Универзитет у Београду, Математички факултет}
% Ime i afilijacija trećeg člana komisije (opciono)
% \komisijaC{}
% Ime i afilijacija četvrtog člana komisije (opciono)
% \komisijaD{}
% Datum odbrane (obrisati ili iskomentarisati narednu liniju ako datum odbrane nije poznat)
\datumodbrane{15. јануар 2025.}

% Apstrakt na srpskom jeziku (u odabranom pismu)
\apstr{%
Нештонешто
}

% Ključne reči na srpskom jeziku (u odabranom pismu)
\kljucnereci{рачунарство, машинско учење, безбедност, криптографија}

\begin{document}
% ==============================================================================
% Uvodni deo teze
\frontmatter
% ==============================================================================
% Naslovna strana
\naslovna
% Strana sa podacima o mentoru i članovima komisije
\komisija
% Strana sa posvetom (u odabranom pismu)
\posveta{Тањи и Ралету}
% Strana sa podacima o disertaciji na srpskom jeziku
\apstrakt
% Sadržaj teze
\tableofcontents*

% ==============================================================================
% Glavni deo teze
\mainmatter
% ==============================================================================

% ------------------------------------------------------------------------------
\chapter{Увод}
% ------------------------------------------------------------------------------


\section{Мотивација}

Криптографски алгоритми који се данас широко користе сматрају се математички безбедним, међутим њихово извршавање на физичким уређајима чини их подложним нападима споредним каналима (енг. {\lat side-channel attacks SCA}). Ови напади користе физичке карактеристике уређаја, као што су потрошња енергије, електромагнетно зрачење или време извршавања, како би се дошло до информација о тајним кључевима који се користе у криптографским операцијама. Иако су први облици ових напада познати још од краја двадесетог века, њихова ефикасност значајно је порасла применом метода машинског учења.

Досадашња истраживања у области {\lat SCA} најчешће користе вишеслојни перцептрон (енг. {\lat multi-layer perceptron - MLP}) и конволутивне неуронске мреже (енг. {\lat convolutional neural network - CNN}). Међутим, развој механизама пажње (енг. {\lat attention}), посебно у оквиру трансформер модела, отворио је нове могућности за побољшање анализе споредних канала. Управо зато постоји потреба да се систематски испита потенцијал ових архитектура и њихова примена у контексту криптографских имплементација.

\section{Циљ рада}

Циљ овог рада је да прикаже потенцијал техника дубоког учења у анализи споредних канала, са посебним нагласком на архитектуре које интегришу механизме пажње. У том контексту, разматране су варијанте {\lat CNN} модела проширене {\lat squeeze-and-excitation (SE)} и {\lat convolutional block attention mechanism (CBAM)} модулима, као и поређење са класичним приступима заснованим на {\lat MLP} и стандардним {\lat CNN} архитектурама.

Истраживање је спроведено над јавно доступним скуповима података, уз додатно коришћење синтетичких трагова генерисаних помоћу {\lat Unicorn} и {\lat Rainbow} алата. Овакав приступ омогућава експериментисање у контролисаном окружењу, без потребе за скупом и тешко доступном лабораторијском опремом. Додатни циљ рада је и испитивање могућности примене напада споредним каналима на {\lat ZephyrOS} апликацију, у сценарију деанонимизације корисника {\lat Bluetooth} уређаја.


\section{Машинско учење}

Методе машинског учења налазе све ширу примену у различитим областима, посебно у обради сигнала и слика. Основни модели као што су вишеслојни перцептрон (енг.~multi-layer perceptron -- MLP) и конволутивне неуронске мреже (енг.~convolutional neural networks -- CNN) већ су показали значајан успех у анализи података који садрже скривене обрасце. У контексту напада споредним каналима, ови модели се користе за аутоматско откривање статистичких веза између осетљивих криптографских променљивих и измерених физичких сигнала.

Новији приступи, који укључују механизме пажње (енг.~attention), додатно проширују могућности машинског учења. Механизам пажње омогућава моделима да сами открију најбитније делове улазних података. У контексту споредних канала, ово одговара задацима проналажења тачака интереса у криптографским траговима, што омогућава ефикаснију и често прецизнију анализу.

\section{Повезани радови}

\subsection{Класични напади споредним каналима}

Област напада споредним каналима није нова. Првобитно коришћење споредних канала за откривање тајног кључа {\lat DPA} алгоритма дефинисао је Пол Кохер (енг.~{\lat Paul Kocher}) са сарадницима \cite{KocherDpa}. На ову идеју надовезао се рад Ерика Бријера (енг.~{\lat Eric Brier}) и сарадника \cite{brier2004correlation}, који користи Пирсонов коефицијент корелације за ефикасније рачунање статистички значајних информација о тајним криптографским променљивим\footnote{У наставку рада користиће се општеприхваћени појам \textit{осетљиве променљиве}.}. 

У раду \cite{chari2002template}, Суреш Чари (енг.~{\lat Suresh Chari}) уводи појам \textbf{напада шаблонима}, који су дуго сматрани најмоћнијим приступом са теоријске стране. Ову класу напада карактерише прављење прецизног статистичког модела (шаблона) цурења за све могуће вредности осетљивих променљивих, што омогућава веома прецизну анализу.

\subsection{Напади машинским учењем}

Развој машинског учења и доступност моћног хардвера довели су до примене дубоких модела у анализи споредних канала. Рад Елеоноре Кагли и сарадника \cite{cagli2017convolutional} показао је да се CNN модели могу користити за напад на криптографске имплементације заштићене мерама као што су насумична кашњења такта, чиме се смањује потреба за компликованим претпроцесирањем трагова. Ово је отворило врата за истраживаче из области обраде сигнала и слика да се укључе у област SCA.

Један од најзначајнијих радова у овој области је анализа Емануела Пруфа и сарадника \cite{prouff2018ascad}, која пореди MLP и CNN моделе, и као додатак представља јавни скуп података {\lat ASCAD}. Овај скуп је постао де-факто стандард за евалуацију нових модела у SCA заједници.

Поред тога, пажња је све више усмерена ка хибридним архитектурама. Радови \cite{hu2019squeezeandexcitationnetworks} и \cite{woo2018cbam} показали су како додавање squeeze-and-excitation (SE) и convolutional block attention mechanism (CBAM) модула CNN архитектурама може побољшати способност модела да се фокусирају на најрелевантније делове улазних података. Ови приступи убрзо су пронашли примену у анализи споредних канала, где се „тачке интереса“ у траговима могу третирати као региони од значаја. 

Даље, радови као што су TransNet \cite{hajra2022transnet} и EstraNet \cite{hajra2024estranet} експлицитно користе концепте из трансформер архитектура \cite{vaswani2017attention} у контексту SCA. Они показују да механизми пажње, првобитно развијени за обраду природних језика, имају велики потенцијал и у криптоанализи.

\section{Структура рада}

Рад је организован на следећи начин. У Поглављу~2 представљене су теоријске основе криптографије, алгоритма AES, напада споредним каналима и метода машинског учења. Поглавље~3 описује методологију истраживања, укључујући скуп података ASCAD, као и алате Unicorn, Rainbow и Lascar, заједно са експерименталном поставком у оквиру оперативног система ZephyrOS. У Поглављу~4 детаљно су описане архитектуре машинског учења које су примењене у анализи, док су резултати и анализа представљени у Поглављу~5. На крају, Поглавље~6 садржи закључке рада и могуће правце будућег истраживања.


\section{Повезани радови}

Област напада споредним каналима није нова, и првобитно коришћење споредних канала за откривање тајног кључа {\lat DPA} алгоритма дефинисао је Пол Кохер (енг. {\lat Paul Kocher}) са сарадницима \cite{KocherDpa}. На ову идеју надовезује се рад \cite{brier2004correlation} Ерика Бријера (енг. {\lat Eric Brier}) и сарадника који користи Пирсонов коефицијент корелације за ефикасније рачунање статистички значајних информација тајних криптографских променљивих\footnote{Овде се користи појам криптографских или тајних променљивих, с тим да ће у наставку рада бити уведен општеприхваћени појам \textit{осетљиве променљиве}}. У \cite{chari2002template} Суреш Чари (енг. {\lat Suresh Chari}) уводи појам \textbf{напада шаблонима} који су дуго сматрани најмоћнијим приступом са теоретске стране. Наиме, ову класу напада карактерише прављење прецизног статистичког модела (шаблона) цурења за све могуће вредности тајних променљивих.


С друге стране, машинско учење је узнапредовало са развојем моћног хардвера. У обради слика веома зу заступљене конволутивне неуронске мреже. Још један битан механизам за машинско учење јесте \textbf{механизам пажње}. Иако је првобитно дефинисан у сврху обраде природних језика од стране Ашиша Васванија и сарадника (енг. {\lat Ashish Vaswani}) у \cite{vaswani2017attention}, након великог успеха предложене архитектуре, трансформера, механизми пажње нашли су своју примену и у обради слике. Радови \cite{hu2019squeezeandexcitationnetworks} од стране Хуа и сарадника и \cite{woo2018cbam} од стране Сангјун Вуа и сарадника (енг. {\lat Sanghyun Woo}) примењују хибридне механизме пажње на обраду слике.

Имајући у виду да напади споредним каналима захтевају конструкцију статистичких модела, и да се често нелинеарне зависности могу корелисати са криптографским операцијама, природно је да се напади могу представити као проблеми машинског учења. На пример, рад Елеоноре Кагли и сарадника (енг. {\lat Eleonora Cagli}), \cite{cagli2017convolutional}, показује да се конволутивне неуронске мреже могу користити за напад криптографских имплементација заштићене мерама као што су насумичним кашњењем сата, и да смањују потребу за компликованим претпроцесирањем трагова. Ово отвара могућности за истраживаче из других области. Један од најутицајнијих радова у овој области јесте подробна анализа алата машинског учења примењеног на класу напада споредним каналима од стране Емануела Пруфа и сарадника: \cite{prouff2018ascad}. Овај рад пореди вишеслојне перцептроне и конволутивне неуронске мреже. Као још један додатан допринос овог рада јесте јавно доступни скупа података {\lat ASCAD} по узору на {\lat MNIST} који истраживачима пружа стандардизовану платформу за поређење и евалуацију нових модела.

Након што је ефикасност машинског учења у овој области потврђена, истраживање је постало усмереније и на друге, комплексније, архитектуре модела. Поменути механизми пажње полако почињу да добијају примену и у нападима споредним каналима. Конволутивне неуронске мреже надограђене су {\lat Squeeze-and-Excitation} слојевима, или {\lat CBAM} слојевима. Ово омогућава моделима да сами ефикасно закључују о најбитнијим деловима измерених трагова, тзв. тачкама интереса. Радови попут \cite{hajra2022transnet} и \cite{hajra2024estranet} користе механизме истражене у конструкцији трансформера (\cite{vaswani2017attention}) специфично за нападе споредним каналима.

Имајући у виду пораст броја уградних уређаја (цитат), њихова безбедност постаје све битнија тема данашњице и у комбинацији са развојем напада споредних канала и машинског учења, јасно је ...


% ------------------------------------------------------------------------------
\chapter{Теоретске основе}
\label{chp:razrada}
% ------------------------------------------------------------------------------

\section{Криптографија}

Основни циљ криптографије је очување поверљивости, интегритета и аутентичности података. Са развојем дигиталне комуникације, симетрична криптографија постала је један од кључних механизама заштите података у свакодневним системима, од интернет комуникација до уградних уређаја.


Симетричне шифре имају две главне варијанте: проточне и блоковске.

\textbf{Проточне шифре} (енг. {\lat Stream Ciphers}) шифрују податке бит по бит или бајт по бајт. Две стране шифроване комуникације договарају се око почетног стања (енг. {\lat seed}) генератора псеудослучајних бројева. Истим генератором и са истим почетним стањем генеришу исти псеудослучајни низ битова, односно низ кључа (енг. {\lat key steam}). На основу тог кључа рачуна се шифрат, веома често коришћењем операције {\lat XOR} ($\oplus$).

\textbf{Блоковске шифре} (енг. {\lat Block Ciphers} шифрују блокове фиксне дужине, односно отворени текст се дели у блокове једнаких дужина и сваки се шифрује засебно. Тајни кључ се договара између страна енкриптоване комуникације и користи се за трансформацију отвореног текста у шифрат. За поруке дуже од једног блока, користе се различити начини надовезивања порука, док се за поруке краће од једног блока користи допуњавање (енг. {\lat padding}).

У овом раду, фокус ће бити стављен искључиво на блоковске шифре и то конкретно на АЕС, који је данас у најширој употреби и детаљније је описан у наредној секцији. Упркос томе, и остале шифре могу бити мета напада споредним каналима .

\section{АЕС алгоритам}

{\lat Advanced Encryption Standard} (АЕС) представља криптографски стандард који је усвојила влада САД. У његовој основи се налази {\lat Rjindael} алгоритам који су развили белгијски криптографи {\lat Joan Daemen} и {\lat Vincent Rijmen}. Често се ова два појма поистовећују, иако је Rjindael прошао ригорозне провере и јавни конкурс који је трајао пет година да би заслужио да се нађе у оквиру AEС стандарда 2001. године.

Дакле, АЕС је блоковска шифра која барата са блоковима дужине 128 бита. Ова шифра је данас у широкој употреби, од обезбеђивања бежичних комуникација (нпр. протокол {\lat WPA2} у оквиру {\lat Wi-Fi} комуникације), и интернет конекција ({\lat SSL/TLS}), заштите хард дискова до коришћења у уградним системима и уређајима интернета ствари (енг. {\lat IoT}). 


У АЕС алгоритму, 128 бита улаза представља се матрицом стања $S$ димензије $4 \times 4$ бајта. Алгоритам се одвија у рундама где се у оквиру сваке рунде матрица стања трансформише дефинисаним операцијама. У зависности од дужине кључа, одвија се различит број рунди:

\begin{itemize}
  \item 10 рунди за кључ дужине 128 бита
  \item 12 рунди за кључ дужине 192 бита
  \item 14 рунди за кључ дужине 256 бита
\end{itemize}

У свакој рунди осим последње примењују се четири трансформације: замена бајтова (енг. {\lat Byte Substitution}), смицање редова (енг. {\lat Shift Row}), мешање колона (енг. {\lat Mix Column}) и додавање кључа рунде (енг. {\lat Add Round Key}). У последњој рунди не примењује се мешање колона.

\subsection{Проширивање кључа}

Постоје варијанте са 128, 192 и 256 битова кључа. Пре почетка шифровања, кључ се проширује у низ кључева рунди (енг. {\lat round keys}) помоћу алгоритма за проширивање кључа (енг. {\lat key schedule}). Сваки кључ рунде је дужине 128 бита, исто као и блок стања.

Проширивање се врши итеративно, односно свака нова реч од 32 бита ($w_i$) генерише се на основу претходне речи ($w_{i-1}$) и од речи са индексом $i-4$ ($w_{i-4}$). Изузетак су прве четири речи које су идентичне улазном кључу. За сваку четврту реч, примењују се следеће операције:

\begin{itemize}
    \item \textbf{RotWord}: Циклично померање бајтова улево за једну позицију
    \item \textbf{SubWord}: Примена функције субституције на сваки бајт у речи
    \item Ексклузивно или ({\lat XOR}) операција са константном вредношћу \textbf{RCON}
\end{itemize}

\subsection{Функција замене бајтова (енг. {\lat SubBytes})}

Функција замене бајтова представља једину нелинеарну операцију у алгоритму и примењује се независно на сваки бајт стања. Имплементира се као табела замене, {\lat Rijndael S-box}. Сама табела је инвертибилна и конструисана је композицијом следећих функција: 

\begin{enumerate}
    \item Мултипликативни инверз у $\mathbf{GF}(2^8)$ где се нула слика у себе
    \item Афина трансформација над пољем $\mathbf{GF}(2)$ дефинисана на следећи начин:
\end{enumerate}

\[
\begin{bmatrix}
y_0 \\
y_1 \\
y_2 \\
y_3 \\
y_4 \\
y_5 \\
y_6 \\
y_7
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 0 & 0 & 1 & 1 & 1 & 1 \\
1 & 1 & 0 & 0 & 0 & 1 & 1 & 1 \\
1 & 1 & 1 & 0 & 0 & 0 & 1 & 1 \\
1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 \\
1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 \\
0 & 1 & 1 & 1 & 1 & 1 & 0 & 0 \\
0 & 0 & 1 & 1 & 1 & 1 & 1 & 0 \\
0 & 0 & 0 & 1 & 1 & 1 & 1 & 1
\end{bmatrix}
\begin{bmatrix}
x_0 \\
x_1 \\
x_2 \\
x_3 \\
x_4 \\
x_5 \\
x_6 \\
x_7
\end{bmatrix}
+
\begin{bmatrix}
1 \\
1 \\
0 \\
0 \\
0 \\
1 \\
1 \\
0
\end{bmatrix}
\]

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{SubBytes.png}
    \caption{Матрица стања пре и после примене функције замене бајтова}
    \label{fig:subBytes}
\end{figure}

Функција {\lat SubBytes} је од посебног значаја у контексту напада споредним каналима, јер представља једину нелинеарну трансформацију у {\lat AES} алгоритму. Излаз из {\lat sbox} табеле се често користи као осетљива променљива у моделима цурења.

\subsection{Функција смицања редова (енг. {\lat ShiftRows})}

Ова функција извршава циклично померање редова улево на следећи начин:

\begin{itemize}
  \item Први ред остаје непромењен
  \item Други ред се помера за једно место улево
  \item Трећи ред се помера за два места улево
  \item Четврти ред се помера за три места улево
\end{itemize}

Слика испод приказује стање пре и после извршавања функције {\lat\textbf{ShiftRows}}:

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{ShiftRows.png}
    \caption{Матрица стања пре и после примене функције {\lat\textbf{ShiftRows}}}
    \label{fig:shiftRows}
\end{figure}

\subsection{Функција мешања колона (енг. {\lat MixColumns})}

Функција {\lat MixColumns} примењује се на сваку колону матрице стања. Бајтови унутар једне колоне се међусобно комбинују применом линеарне трансформације у пољу $\mathbf{GF}(2^8)$. Све рунде осим последње примењују ову функцију. Еквивалентно, операција се може представити као множење сваке колоне векторa са следећом матрицом у $\mathbf{GF}(2^8)$:

\[
\begin{bmatrix}
02 & 03 & 01 & 01 \\
01 & 02 & 03 & 01 \\
01 & 01 & 02 & 03 \\
03 & 01 & 01 & 02
\end{bmatrix}
\]

Слика \ref{fig:mixCols} приказује стање пре и после извршавања функције {\lat\textbf{MixColumns}}:

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{MixCols.png}
    \caption{Матрица стања пре и после примене функције {\lat\textbf{MixColumns}}}
    \label{fig:mixCols}
\end{figure}

\subsection{Функција додавања кључа рунде (енг. {\lat AddRoundKey})}

У овом кораку, одговарајући кључ рунде се комбинује са тренутном матрицом стања помоћу битовске операције {\lat XOR} ($\oplus$). Ово је једина операција која директно користи тајни кључ, због чега има 
кључну улогу у безбедности алгоритма. Без овог корака остале трансформације не би могле саме да обезбеде криптографску заштиту.

\subsection{Начини коришћења (надовезивања) блоковских шифри}

С обзиром да АЕС алгоритам ради само над блоковима фиксне дужине, неопходно је дефинисати процедуру за краће или дуже поруке. Главни режими за надовезивање су:

\begin{itemize}
    \item \textbf{\lat ECB (Electronic Code Book)} представља просто надовезивање блокова. Најједноставнији је, али и најнесигурнији, пошто исти блокови дају исти шифрат.
    \item \textbf{\lat CBC (Cipher Block Chaining)} уводи иницијализациони вектор ({\lat IV}) који помаже у томе да се исти блокови сликају у различите шифрате.
    \item \textbf{\lat CTR (Counter)} користи бројач који претвара блоковску шифру у проточну.
\end{itemize}

Због своје једноставности, {\lat ECB} се неретко користи у уградним уређајима за кратке поруке. ECB ће бити посебно занимљив у контексту ZephyrOS-а, конкретно приликом генерисања RPA.


% ------------------------------------------------------------------------------

\section{Напади споредним каналима}

Иако су криптографски алгоритми који су у широкој употреби данас прошли кроз ригорозне теоретске и емпиријске експерименте, и достигнут је консензус да је већина њих безбедна (изузимајући пост-квантну криптографију), сама софтверска или хардверска имплементација може увести нове правце напада на алгоритам, без нарушавања његове теоретске заснованости. Наиме, напади који користе споредне ефекте извршавања ових алгоритама, односно споредне канале, престављају растући проблем у практичној примени криптографије. Неки од напада користе особине самог хардвера на коме се извршавање дешава, мерећи електромагнетно зрачење, магнетно поље, температуру или време извршавања и на основу сакупљених мерења проналазе повезаност између тајних кључева и измерених физичких величина.

\subsection{Примери напада}

Сликовит пример је тзв. Вашингтонски пица индекс (\cite{ProleWiki_2025}, \cite{TheEconomicTimes}): није познато од када ова идеја постоји, али се понекад везује за хладни рат и шпијунске технике. Наиме, идеја је да је број достава пице у комплексу америчке беле куће или Пентагона јасно индикује да је на реду нека криза јер владини агенти раде до касно у ноћ и може се приметити јасан пораст достава у односу на миран период. Дакле, иако је сигурност комуникације и физичког приступа на веома високом нивоу (у већини случајева), уочено је цурење информација тзв. споредним каналима, односно бројем достављених пица у оквиру комплекса (мање-више јавно доступне информације). Наравно, ови наводе америчка влада није коментарисала и није спроведено аутентично и независно истраживање које би оповргло или потврдило тврдње. У сваком случају идеја је веома блиска начину на који напади споредним каналима функционишу.

Још један, мало уже везан пример за криптографију јесте алгоритам степеновања квадрирањем. Овај алгоритам линеарно зависи од броја јединица у бинарном запису тајног кључа. Само број јединица није довољан да се открије кључ, али велики број понављања алгоритма са истим кључем и различитим улазима, омогућава нападачу да прикупи довољно информација како би обавио статистичку анализу и открио тајни кључ. Један од познатих алгоритама који користе степеновање на овај начин јесте {\lat RSA}. \cite{brumley2005remote} показује практичну примену напада споредним временским каналима на имплементацију {\lat SSL} протокола који у основи користи {\lat RSA} алгоритам.

\subsection{Основни споредни канали}

За разлику од класичне криптоанализе, којој је фокус на теоретским и математичким особинама алгоритма, напад споредним каналима (енг. {\lat Side Channel Analysis - SCA} покушава да нападне саму имплементацију на физичком уређају. Ови напади се заснивају на чињеници да физички уређаји, по својој природи, током рада "цуре" информације о операцијама које обрађују. У већини модерних {\lat CMOS} (енг. {\lat complementary Metal-Oxide-Semiconductor}), потрошња енергије је везана за промену логичког стања транзистора из нуле у јединицу и обрнуто. Када се подаци померају дуж магистрале података у процесору, могуће је уочити осцилације у потрошњи енергије, и она је у директној корелацији са подацима који се обрађују. Ово је главна мета за нападаче.
 Ово цурење се може уочити кроз разне споредне канале као што су:

\begin{itemize}
    \item Потрошњи електричне енергије
    \item Електромагнетно зрачење
    \item Топлотно зрачење
    \item Акустични сигнали
    \item Трајање извршавања операција
    \item Кеш меморија и меморијски приступи
    \item Гранања у извршавању програма (енг. {\lat branch prediction})
\end{itemize}

% Опис специфично везан за меморијске магистрале, мерење електричне енергије, акустичних сигнала, сетап, осцилатори, типови напада (профајлинг итд.). Тренинг модела (било стат. било мл.). ДПА, темплејт формуле итд.

Напад се може поделити на \textbf{прикупљање трагова} (мерење), и њихову \textbf{анализу}, односно конструкцију модела (било статистичког или модела заснованог на машинском учењу).

Процес прикупљања трагова захтева посебну лабораторијску опрему, као што су осцилоскоп, електромагнетне сонде, специјализовани звучници и други. Типична поставка, приказана на слици \ref{fig:sca_setup} приказује уређај под нападом, дигитални осцилоскоп и одговарајуће сонде за мерење физичких сигнала.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{oscilloscopeSetup.png}
    \caption{Опрема за прикупљање сигнала уређаја под нападом \cite{karayalcin2025practical}}
    \label{fig:sca_setup}
\end{figure}

\subsection{Модели цурења}

Када се говори о споредним каналима, један од кључних појмова јесте модел цурења канала (енг. {\lat leakage model}). Наиме, статистички значајне информације цуре као последица физичке имплементације алгоритама. Да би се ово ненамерно цурење дефинисало, уводе се различити типови функција које настоје да прецизно моделују цурење.

Најчешће коришћени модели су:

\begin{itemize}
    \item \textbf{Хамингова тежина} дефинише се као број јединица у оквиру броја у бинарном запису. Претпоставка је да потрошња енергије зависи од броја битова који су постављени на 1.
    \item \textbf{Хамингова раздаљина} дефинише се као број битова који се разликују у два бинарна броја. У контексту напада споредним каналима, ова два броја су две узастопне вредности на магистрали података. Овај модел је повезан са {\lat CMOS} технологијом где потрошња највише зависи од промене стања битова. TODO: ref
    \item \textbf{Модел идентитета} претпоставља да цурење директно зависи од саме вредности податка који се обрађује.
\end{itemize}

\subsection{Типови напада}

Угрубо, напади споредним каналима могу се поделити на две класе у зависности од способности нападача:


\subsection{Напади без профилисања}

Ову класу напада карактерише то што нападач нема приступ идентичном уређају за "тренирање", већ користи само измерене физичке величине са циљног уређаја. Над овим подацима се спроводе статистичке анализе у нади да се открије зависност међу подацима и осетљивим променљивама. Често се користи Пирсонова корелација, разлика средњих вредности. Примери су једноставна анализа енергије (енг. {\lat simple power analysis - SPA}, и диференцијална анализа енергије (енг. {\lat differential power analysis - DPA}). {\lat DPA} обично врши статистичку анализу трагова како би се откриле мале корелације између потрошње енергије и података који се обрађују. Из тог разлога, {\lat DPA} захтева велики број трагова.

\subsection{Напади профилисањем}

Ову класу напада карактерише способност нападача да у потпуности контролише систем, односно и отворен текст, и кључ. Такође, нападач има приступ "клонираном" уређају који у великој мери одговара мети. Нападач прави \textit{профил} уређаја. На први поглед делује неинтуитивно како би овај напад могао бити користан уколико је нападачу већ све омогућено, али у реалним условима, већина масовно произведених уградних уређаја има исте хардверске карактеристике (и може се сматрати да спроводи мање више исте криптографске операције). Дакле, прављењем успешног модела за једну фамилију уређаја са истим чипом, од истог произвођача, отвара могућност напада на све уређаје из те класе. Нападач је овде "свемоћан", што је, наравно, теже остварити у пракси. 

Напади профилисањем спроводе се у две етапе:

\begin{itemize}
    \item \textbf{Фаза профилисања}: Нападач користи клониран уређај да направи модел цурења
    \item \textbf{Фаза напада}: На основу изграђеног модела, нападач прикупља до сада невиђене трагове са циљног уређаја и покушава да извуче тајну променљиву
\end{itemize}

Током прве фазе напада, нападач предвиђа условну вероватноћу

$$\mathrm{Pr}[\mathbf{X}|Z = z]$$

из скупа за профилисање ${\{\mathbf{x}_i, z_i}\}_{i=1,...,N_p}$ величине $N_p$, односно скуп прикупљених трагова $\mathbf{x}_i$ при познатој вредности $z_i$ циљне променљиве.

Један од најпознатијих примера ових напада јесте напад шаблонима \cite{chari2002template}: конструише се статистички модел ("шаблон") који описује расподелу цурења споредног канала и шума за сваку могућу вредност осетљиве променљиве. У фази напада, трагови се упоређују са дефинисаним шаблонима да би се пронашло најбоље поклапање.



\subsection{Диференцијална анализа напона \lat{DPA}}

Још један од битних метода за откривање тајних кључева на основу измерене јачине струје (напона), јесте диференцијална анализа струје (енг. {\lat Differential Power Analysis - DPA}). У свом раду, Пол Кохер \cite{KocherDpa} појашњава методологију везану за анализу енергије. Овај рад се често сматра првим у области напада споредним каналима. С обзиром да се алгоритми извршавају на полупроводничким чиповима, могуће је мерити потрошњу електричне енергије уз помоћ осцилоскопа. Најједноставнији вид анализе јесте резоновање о програму или делу програма који се извршава на основу графичког приказа потрошње електричне енергије у том тренутку. Овај вид анализе назива се једноставна анализа енергије (енг. {\lat Simple Power Analysis - SPA}. Искусни експерти могу, у случају једноставних и незаштићених криптографских алгоритама, јасно издвојити различите фазе алгоритма. Пример измерене електричне енергије у случају DES алгоритма дат је на слици испод:

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.5\textwidth]{SPA_DES.png}
  \caption{Измерена електрични напон током читавог извршавања ДЕС алгоритма}
  \label{fig:spa_des}
\end{figure}


Уводимо још један битан појам за нападе споредним каналима, а то је \textbf{траг} (енг. trace). За трагове је такође битно споменути и резолуцију, односно изражајност трага. На пример, могуће је додатно повећати фреквенцију прикупљања трагова и на тај начин ефективно зумирати графикон, који може пружити више детаља особи која анализира ове податке. Битне особине на које се анализатор фокусира јесу делови трага у којима се јасно виде разлике између јединица и нула, односно места на којима долази до разилажења трага.

Конкретно, у случају DPA на ДЕС алгоритам, нападач дефинише функцију селекције, $D(C, b, K_s)$ где је $C$ шифрат, $0 < b < 32$ је бит који покушавамо да предвидимо, а $K_s$ је тајни кључ у оквиру 16. рунде ДЕС алгоритма (детаље самог алгоритма погледати у рефТОДО). Напад се састоји у прикупљању $m$ трагова, са по $k$ тачака у сваком, односно $T_{1..m}[1..k]$ и $C_{1..m}$ шифрата. Напад се своди на погађање бита кључа и рачунање корелације између тог нагађања и трага, односно уколико смо погодили кључ, очекујемо да ће и трагови то потврдити. Поближе, 
Нападач даље рачуна разлику између ... и ...
У случају када је нагађање за кључ $K_s$ нетачно, функција селекције би требало да тежи нули како се број трагова приближава бесконачности. Насупрот томе, у случају тачног погађања, 

Овај процес може се и графички интерпретирати, односно уколико се исцрта график диференцијалног трага, очекује се да временске тачке у којима не постоји корелација између бита кључа и измерене енергије, буду блиске нули, односно "равне", док на местима где се дешава цурење, очекујемо нагле скокове (енг. {\lat spike}).

\subsection{Корелациона анализа напона}

Надограђујући идеју из претходног сегмента, уводимо и појам корелационе анализе напона. 

\subsection{Напади шаблонима (енг. {\lat Template attack})}

Од досада разматраних напада коришћењем споредних канала, напад у овом делу носи највећу комплексност. Стога, неће у потпуности бити описан, већ у смислу поређења са главном темом овог рада. Иако су перформансе пре увођења машинског учења биле највеће за ове нападе. Свакако, биће дата интуиција и оквиран увод, са напоменом да дубље истраживање излази из оквира овог рада

Уводи се појам \textbf{осетљиве променљиве (енг. {\lat sensitive variable})}, односно променљиве за коју се надамо да ће произвести најпогодније цурење - оно које је значајно корелисано са тајним вредностима (кључа). Честа мета напада је, на примеру АЕС алгоритма, излаз из {\lat SBOX} табеле у првој рунди енкрипције. Та вредност је оно што је, у овом случају, осетљива променљива. Битно је мерити електричну енергију приликом баратања осетљивим променљивама, нпр. приликом коришћења табеле {\lat SBOX}, односно када се вредности учитају на магистралу података.



\textbf{Статистички модели:} код традиционалних напада, као што су напади шаблонима, процес се састоји из рачунања вероватноћа за све хипотезе кључа тако што се сабирају логаритмована предвиђања хипотеза кључа над целим скупом података. 

$$ S_k = \sum_{i=0}^{N-1} predictions\_{log}_i[ hypothetical\_label_i(k)] $$

$S_k$ је оцена за хипотезу да је кључ $k$, $N$ је укупан број трагова у скупу за напад, $predictions\_{log}_i$ је вектор логаритмованих вероватноћа за све могуће ознаке трага $i$

\textbf{Модели машинског и дубоког учења:} у последње време, све је већи број експеримената и радова који користе дубоко учење за нападе и показује се да су чак и ефикаснији од традиционалних статистичких модела, као и да су мање подложни мерама заштите као што су маскирање, насумично окидање сата (енг. {\lat random clock jitter}) и десинхронизација. Такође, дубоко учење има предност у томе што се тачке интереса (енг. {\lat points of interest - POI} не морају нужно ручно конструисати, већ модел сам може да научи који делови трага садрже најрелевантније информације. Ово су тачке у трагу код којих се јавља највеће цурење, односно где очекујемо да можемо извући највише информација - најитересантније тачке.

Неке од мана модела машинског и дубоког учења јесу одабир хиперпараметара (као и архетутуре мрежа) о чему ће бити речи у одељку везаном за експерименте и конкретну имплементацију. Неки радови уводе технике као што су аутоматска претрага хиперпараметара (рефс хере), али о томе неће бити речи у овом раду.

Такође, као и код модела машинског учења за друге проблеме, објашњивост научених параметара и конкретно разумевање архитектуре јесте активна област истраживања.

Уобичајени модели су:

\begin{itemize}
    \item Вишеслојни перцептрон (енг. {\lat Multilayer Perceptron - MLP}
    \item Конволутивне неуронске мреже
    \item Резидуалне мреже
    \item Трансформери (у скорије време)
    
\end{itemize}

\subsection{Метрике за процену цурења}

\subsubsection{Однос сигнала и шума (енг. {\lat Signal to Noise Ratio - SNR}}

У најопштијем смислу, ова метрика омогућава да се на први поглед процени степен цурења неке осетљиве променљиве. Квантификује се величина корисног сигнала (у овом случају степен цурења) у односу на присуство насумичног шума у измереним подацима.

Нека је $L_d$ детерминистички део зависан од осетљиве променљиве $V$, $L_n$ насумични шум (може се претпоставити гаусова расподела $\mathcal{N}(0, \sigma^2)$).

Тада важи:
$$L = L_d + L_n = g(V) + L_n$$

Однос сигнала и шума дефинише се као:

$$SNR = {\mathbf{Var}(L_d) \over{\mathbf{Var}(L_n)}}$$

У одређеној временској тачки, вредност {\lat SNR} величине сразмерна је јачини цурења, односно веће вредности индикују јаче цурење и обратно. Други начин рачунања ове метрике (која се некад назива и Фишеров тест) јесте следећи:

$$SNR = {\mathbf{Var}[\mathbf{E[}(L_t | Z]]) \over{\mathbf{E}[\mathbf{Var}(L_t|Z)]}}$$ 

Где је $Z$ неки догађај

\subsection{Технике заштите}

Једна од најпроучаванијих мера заштите од оваквог типа напада јесте \textbf{маскирање} (енг. {\lat masking}). Основна идеја маскирања јесте увођење насумичних вредности (маски) приликом извршавања криптографског алгоритма. Циљ уведених вредности јесте да се "разбије" корелација између потрошње електричне енергије и осетљивих межувредности чиме се нападачу значајно отежава извлачење тајног кључа. Дакле, ово је заштита на алгоритамском нивоу (иако може бити имплементирана хардверски) и зависи од самог алгоритма, односно маскирање у АЕС алгоритму разликује се од маскирања у ДЕС алгоритму. 

\subsubsection{Булово маскирање}

Маскирање се заснива на принципу дељења тајне (енг. {\lat secret sharing}), односно дељење тајне променљиве на делове које ће алгоритам обрађивати уместо саме тајне. У симетричним алгоритмима, попут АЕС-а, често се користи \textbf{булово маскирање}.

Код \textbf{Буловог маскирања}, тајна вредност $s$ дели се на $d + 1$ делова (енг. {\lat shares}) $s_0, s_1, ... , s_d$ тако да важи:

$$s = s_0 \oplus s_1 \oplus ... \oplus s_d$$

Параметар $d$ се назива \textbf{степен маскирања} (енг. {\lat masking order}). Да би нападач реконструисао тајну променљиву $s$, мора поседовати знање о свих $d + 1$ делова истовремено. Напади који циљају имплементацију заштићену $d$-тог реда, називају се напади вишег реда (енг. {\lat higher-order attack}), и комплексност напада расте са редом маскирања. У овом раду, фокус је на маскирању првог реда ($d = 1$), где се тајне деле на два дела: $s = s_0 \oplus s_1$.

На овај начин, конкретна тајна вредност се ни у једном тренутку не користи у алгоритму, већ се све обавља над дефинисаним деловима.

\subsubsection{Маскирање линеарних и нелинеарних операција АЕС алгоритма}

У зависности од тога да ли је операција линеарна или не у ондосу на {\lat XOR} операцију, примењују се различите технике маскирања.

\textbf{Линеарне операције}, попут \lstinline{ShiftRows, MixColumns, AddRoundKey} једноставно је маскирати. Из дефиниције линеарности ($F(s_0\oplus s_1) = F(s_0) \oplus F(s_1)$, следи да се маскирање може применити на сваки део независно. На пример, за \lstinline{AddRoundKey} важи:

$$(s_0 \oplus s_1) \oplus k = (s_0 \oplus k) \oplus s_1$$

Односно, довољно је извршити операцију {\lat XOR} само над једним делом, док други остаје неизмењен.

\textbf{Нелинеарне операције}, попут \lstinline{SubBytes} су већи изазов за маскирање. Наиме, код {\lat SBOX} не важи дистрибутивност:

$$S(s_0 \oplus s_1) \neq S(s_0) \oplus S(s_1)$$

Стога, не може се применити операција над сваким делом засебно, већ је неопходно развити комплексније алгоритме. Ови алгоритми уводе временску или просторну сложеност и представљају већински удео "цене" примене заштите. Приступ коришћен у овом раду биће описан у поглављу "Методологија рада".

Осим буловског постоје и друге врсте маскирања, попут аритметичког, афиног и других. Развој маски такође представља широку област истраживања, али фокус овог рада неће бити на осталим методама.

\section{Машинско учење}

У најопштијем смислу, машинско учење представља...

МЛ, дубоки МЛ, дискриминативни-генеративни модели. Архитектуре мрежа - МЛП, ЦНН, трансформери. Тренинг модела, евалуација модела. Механизми пажње - СЕ, ЦБАМ.. 

\subsection{Конволутивне неуронске мреже}

Конволутивне неуронске мреже се показују добро на сликама од свог настанка (ТОДО додај референце). Разлог за добре перформансе, вероватно лежи у томе што операција конволуције условљава мрежу да учи на основу локализованих шаблона у оквиру слика. 
Осим првобитне примене у раду са сликама, односно дводимензионалним подацима, конволутивне мреже налазе примену и у секвенцијалним подацима, као што су временске серије и др. У овом случају реч је о једнодимензионим конволутивним мрежама. Трагови над којима се врши анализа споредних канала такође представљају временске серије, и такође природно имају темпоралне зависности између разних тачака.


\subsection{{\lat Squeeze-and-Excitation} неуронске мреже}
\label{subsec:se_block}

\cite{hu2019squeezeandexcitationnetworks} уводи нови тип градивног блока за конволутивне неуронске мреже. У класичним конволутивним мрежама, међузависности канала су локалне и имплицитне, те је идеја аутора била да се уведе механизам који би наученим конволутивним атрибутима придао значај баш на основу релација између самих канала. На слици \ref{fig:se-block} приказана је архитектура једног {\lat SE} блока у дводимензионалном случају. $F_{tr}: \boldsymbol{X} \in \mathbb{R}^{H \times W \times C}$ представља функцију трансформације улаза, у овом случају, конволуцију. Њеном применом добија се низ $C$ научених филтера где је сваки димензије $H \times W$. То је матрица $U$ која представља улаз самог {\lat SE} блока. Ближе, матрица $U$ дефинише се вектор елемената $u_c$, где је:

$$u_c = v_c * \boldsymbol{X} = \sum_{x=1}^{C'} v_c^s * x^s$$

а $V = [v_1, v_2, ..., v_C]$ представља научене филтер кернеле, док $x$ представља улазне елементе. 

На овако конструисане $u_C$ примењује се \textbf{операција сабијања} (енг. {\lat squeeze}) којој је циљ да свим каналима додели опис канала (енг. {\lat channel descriptor}. Ово је оправдано чињеницом да научени филтери немају никакве информације о осталим каналима. Сам механизам представља глобално упросечавање (енг. {\lat global average pooling}) које за резултат има \textbf{дескриптор канала}. Свака од поменутих карактеризација дефинише се на следећи начин:

$$z_c = \boldsymbol{F_{sq}}(u_c) = {1 \over{H \times W}} \sum_{i=1}^H \sum_{j=1}^W u_c(i, j)$$

Применом на све филтере, добија се вектор величине $C$ где сваки елемент одговара десктриптору једног канала. Осим глобалног упросечавања, могуће је користити и неку компликованију операцију смањења димензионалности.

На основу израчунатих дескриптора канала, циљ је израчунати међузависности канала. 

$$s = \mathbf{F_{ex}}(\mathbf{z, W}) = \sigma(g(\mathbf{z,W})) = \sigma(\mathbf{W_2}\delta(\mathbf{W_1z}))$$

$\delta$ је овде {\lat ReLU} активациона функција, $\mathbf{W_1} \in \mathbb{R}^{{C \over r} \times C}$ и $\mathbf{W_2} \in \mathbb{R}^{C \times {C \over r}}$. Овако конструисана операције \textbf{ексцитације} (енг. {\lat excitation}) испуњава 2 битне особине:

\begin{enumerate}
    \item Способност учења нелинеарних зависности међу каналима
    \item Омогућено је неексклузивно придавање значаја каналима
\end{enumerate}

Такође, матрице $\mathbf{W_1}$ и $\mathbf{W_2}$ представљају два потпуно повезана слоја: \textbf{слој смањења димензионалности} који улазе скалира параметром $r$ и \textbf{слој повећања димензионалности} који улаз враћа на првобитну димензионалност. Параметар $r$ представља хиперпараметар и биће мета штимовања мреже у конкретној имплементацији.

На крају, научене значајности канала множе се са оригиналним улазима како би дошло до њиховог појачавања или смањења.

$$\tilde{x}_c = \mathbf{F_{scale}}(\mathbf{u_c}, s_c) = s_c\mathbf{u_c}$$

Другим речима, множе се филтери $\mathbf{u_c} \in \mathbb{R}^{H \times W}$ (кернели фичр мапе??) са скаларом $s_c$. Интеграција у архитектуру постојеће неуронске мреже може се обавити тако што се {\lat SE} блокови уметну након нелинеарности после сваке конволуције. Више речи о конкретним имплементационим изборима биће дато у поглављу \ref{chp:cnnseimpl}.


\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{SEblock.png}
    \caption{{\lat SE} блок \cite{hu2019squeezeandexcitationnetworks}}
    \label{fig:se-block}
\end{figure}

\subsection{{\lat Convolutional Block Attention Module} неуронске мреже}

Блиско идеји из претходног одељка, аутори рада \cite{DBLP:journals/corr/abs-1807-06521} уводе надоградњу {\lat SE} блока увођењем новог блока - {\lat CBAM}. Како наводе, механизми пажње играју улогу и у начину како човек перципира свет око себе, односно не процесуира се читаво видно поље одједном, већ се људи фокусирају на такорећи најинтересантније секторе видног поља како би се боље ухватила суштина онога што се посматра. Иако се позивају на \cite{hu2019squeezeandexcitationnetworks} и њихов допринос у извлачењу зависности међу каналима, уочавају да коришћење глобалног упросечавања (енг. {\lat Global average pooling - GAP}) има проблем код уочавања суптилних тачака пажње у оквиру канала. Такође наводе да аутори поменутог рада не пропуштају да ставе фокус просторну пажњу, односно \textbf{где} се треба фокусирати. Стога, предлажу коришћење и глобалног максимизовања (енг. {\lat Global Maximum Pooling - GMP}) као додатак {\lat GAP}, просторну али и пажњу унутар канала.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{CBAM_fig.png}
    \caption{Приказ {\lat CBAM} блока \cite{DBLP:journals/corr/abs-1807-06521}}
    \label{fig:cbam-block}
\end{figure}

На слици \ref{fig:cbam-block} приказан је концептуално {\lat CBAM} блок док ће у наставку бити описан и са математичке стране.

Уколико је дата мапа атрибута (енг. {\lat feature map}) $\mathbf{F} \in \mathbb{R}^{C \times H \times W}$, {\lat CBAM} модел учи пажњу канала (енг. {\lat channel attention})  и просторну пажњу (енг. {\lat spatial attention}) редом. Први подмодул подсећа на {\lat SE} блок у томе што ...

\begin{equation}
\begin{split}
\mathbf{F' = M_c(F) \otimes F} \\
\mathbf{F'' = M_s(F') \otimes F'}
\end{split}
\end{equation}

$\otimes$ је множење елемент по елемент, $\mathbf{M_c}$ је мапа пажње по каналу $\mathbf{M_c} \in \mathbb{R}^{C \times 1 \times 1}$, $\mathbf{M_s}$ је мапа просторне пажње $\mathbf{M_s} \in \mathbb{R}^{1 \times H \times W}$.

\textbf{Мапа пажње канала}: слично као код {\lat SE} блокова, циљ је извући информације о значајностима појединачних канала. То се постиже тако што се просторна димензија ($\mathbf{H \times W}$) "сужава" помоћу упросечавања. Уз упросечавање, додаје се и максим у исто време. Најпре се примене обе операције смањења димензија које производе два дескриптора канала - $\mathbf{F_{avg}^c}$ и $\mathbf{F_{max}^c}$, оба димензије ${C \times 1 \times 1}$. Оба дескриптора се затим пропуштају кроз вишеслојни перцептрон и сабирају се елемент по елемент како би се добила мапа просторне пажње $\mathbf{M_c}$. Сама мрежа има један скривени слој димензије $\mathbb{R}^{{C\over{r}} \times 1 \times 1}$. Дакле, ова мапа може се представити као:

$$\mathbf{M_c(F)} = \sigma(\mathbf{W_1(W_0(F_{avg}^c})) + \mathbf{W_1(W_0(F_{max}^c)))}$$

$\sigma$ је сигмоидна функција, $\mathbf{W_0} \in \mathbb{R}^{{C \over r} \times C}$ и $\mathbf{W_1} \in \mathbb{R}^{C \times {C \over r}}$ су матрице тежина вишеслојног перцептрона, и $r$ је редукциони параметар, слично као у \ref{subsec:se_block}.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{channel_attn_module.png}
    \caption{Рачунање мапе пажње канала \cite{DBLP:journals/corr/abs-1807-06521}}
    \label{fig:cbam_channel_attn}
\end{figure}

\textbf{Мапа просторне пажње}: за разлику од мапе пажње канала, идеја је фокусирати се на тражење "где" се налази део улаза који је најинформативнији. Конструише се на следећи начин: најпре се примењују упросечавање и максим, али овог пута дуж осе канала. На овако добијен дескриптор атрибута, примењује се конволуција како би се добила $\mathbf{M_s} \in \mathbb{R}^{1 \times H \times W}$ која носи информације \textit{где} се треба више а где мање фокусирати. Дакле, након примене ових операција добијају се дескриптори \textbf{атрибута} $\mathbf{F_{avg}^s}$ и $\mathbf{F_{max}^s}$, оба димензије ${1 \times H \times W}$. Ови дескриптори се након тога пропуштају кроз класичан конволутивни слој. Дакле,

$$\mathbf{M_c(F)} = \sigma(f * ([\mathbf{F_{avg}^s;F_{max}^s}])$$

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{spatial_attn_module.png}
    \caption{Рачунање мапе просторне пажње \cite{DBLP:journals/corr/abs-1807-06521}}
    \label{fig:cbam_spatial_attn}
\end{figure}

\subsection{Механизми пажње}

На идеју конволуција надограђују се механизми пажње. Рад "Пажња је све што ти је потребно" енг. {\lat Attention is All You Need}\cite{vaswani2017attention} уводи ове појмове и нову архитектуру, трансформер. Уместо локалних атрибута, гледају се сви парови атрибута .. Квадратна сложеност је један од великих проблема приликом развоја ових архитектура. Из тог разлога, доста радова се бави управо смањењем времена и сложености тренинга. Навести папире, линформер перформер итд.
Механизми пажње настоје да опонашају људски начин размишљања, односно да моделима омогуће селективно фокусирање на одређене делове улазних података који су, вероватно, битнији од осталих. С математичке стране, ови механизми уводе тежинске суме везане за разне делове улазних података, где тежине означавају битност неког дела улаза, док се небитни делови ефективно игноришу (или им се пак придаје знатно мање пажње). За разлику од рекурентних неуронских мрежа, где је био уочљив проблем код дугорочних зависности (далеких, где је долазило до нестајућих градијената), механизми пажње се понашају знатно боље јер се направљене матрице фокусирају на читав улаз одједном. Додатно, механизми само-пажње (енг. {\lat self-attention}) ...

Усмеравање (пажње) мреже на одређене делове улаза..

У контексту напада споредним каналима, нема пуно радова, али се трансформер уводи у оквиру рада \cite{hajra2022transnet}, који исти аутори касније надограђују у \cite{hajra2024estranet}, однсоно модификују увођењем новог, гаусовског, механизма пажње ({\lat GaussiP}) линеарне сложености. Интуиција је да у нападима споредним каналима, блиске временске тачке имају више утицаја на цурење информација, те се ове главе пажње фокусирају на уже делове трага.

% ------------------------------------------------------------------------------
\chapter{Методологија рада}
\label{chp:methodology}

Ово поглавље има за циљ да представи конкретне кораке у виду реализације експеримената. Најпре, биће описан првобитни скуп података над којим је примењена анализа, након тога описани су алати и методологија за креирање сопствених трагова, и на крају, описан је практичан напад на имплементацију једноставне {\lat bluetooth} апликације.

\section{{\lat ASCAD} скуп података}

Аутори {\lat ASCAD} скупа података водили су се идејом да 
Како би истраживачи који се баве анализом споредних канала имали добар основни скуп података на коме би проверавали перформансе својих модела, уведен је {\lat ASCAD} скуп података по узору на МНИСТ скуп података за обраду слика. Наиме, истраживачи из француске агенције за сајбер безбедност (ANSSI), представљају стандардизован скуп података специфично везан за нападе споредним каналима и то методама дубоког учења. Осим скупа података, који је споредан производ рада, аутори су представили и основе коришћења машинског учења за поменуту класу напада. 

Трагови у оквиру скупа добијени су мерењем електромагнетног зрачења {\lat Atmel ATMega8515} микроконтролера током извршавања софтверске имплементације АЕС-128 алгоритма. Сам алгоритам је написан у асемблерском језику и примењено је маскирање првог реда. Самим тим што онемогућава једноставније нападе првог реда, попут {\lat DPA}, маскирање подиже степен напада који је неопходан за откривање кључа и природно поставља терен за нападе који користе машинско учење и пружа платформу за тестирање ефикасности модела машинског учења да превазиђу овај тип распрострањене заштите.

Скуп података је ускладиштен у {\lat HDF5} формату и подељен је на две групе које одговарају методологији напада профилисањем:

\begin{itemize}
    \item Скуп за профилисање ({\lat Profiling traces}) садржи 50.000 трагова прикупљених у току извршавања алгоритма са познатим, фиксним кључем. У контесту машинског учења, ово је тренинг скуп. Често се овај скуп користи и као извор валидационог подскупа.
    \item Скуп за напад ({\lat Attack traces}) садржи 10.000 трагова прикупљених са \textbf{истим} кључем. Овај скуп служи за тестирање модела.
\end{itemize}

Структура скупа поближе је приказана на слици \ref{fig:ascad-data-structure}:

\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{ASCAD_structure.png}
    \caption{Структура {\lat ASCAD}\cite{prouff2018ascad} скупа података}
    \label{fig:ascad-data-structure}
\end{figure}

\begin{itemize}
    \item \lstinline{traces} Низ измерених трагова електромагнетног зрачења. У оквиру \lstinline{ASCAD.h5f} датотеке сваки траг садржи 700 временских тачака. Овај низ је подскуп сирових трагова () усмерен на регион цурења другог бајта првог излаза {\lat SBOX}-a. Могуће је генерисати и друге подскупове у зависности од циљаног бајта, али тај корак може захтевати додатно препроцесирање и анализу тачака интереса. У већини литературе, овај скуп се користи баш на трећем бајту.
    \item \lstinline{labels} Ознаке које представљају тачну класу циљне променљиве. У овом случају то је $S(p[2] \oplus k[2])$, где је $p[2]$ трећи бајт улазног текста, а $k[2]$ трећи бајт тајног кључа.
    \item \lstinline{metadata} Додатни подаци за сваки траг: свих 16 бајтова отвореног текста, свих 16 бајтова тајног кључа и маске. Из угла машинског учења, ови подаци су бескорисни, јер су само ознаке класа довољне, али из угла напада се на основу метаподатака рачуна естимација бајта кључа $k\hat{}$.
\end{itemize}

\section{{\lat Unicorn} алат за емулацију}

С обзиром на споменута ограничења приликом прикупљања трагова, истражени су алати за емулацију чипова на којима се криптографски алгоритми извршавају. Unicorn алат заснован је на QEMU емулатору, са додатном напоменом да се Unicorn фокусира искључиво на централну процесорску јединицу и њену емулацију. Алат користи QEMU емулацију CPU-a у основи, али пружа и додатне могућности. Још неке од предности у односу на QEMU које аутори алата наводе јесу и проширивост, односно могућност надградње њиховог framework-a. Управо ова особина је омогућила имплементацију специјализованих алата за анализу споредних канала.

\section{{\lat Rainbow} алат за генерисање трагова}

Компанија {\lat Ledger} која се бави производњом крипто новчаника је развила алат који служи за прављење трагова у контексту напада споредним каналима. Идеја је да се истраживачима и компанијама пружи приступачан алат за емулацију и иницијално тестирање сигурности криптографских имплементација без скупог хардвера.

У оквиру овог рада, {\lat Rainbow} је коришћен за генерисање трагова 

\subsection{Скрипте за генерисање трагова}

У циљу аутоматизованог генерисања вештачких трагова, имплементиране су скрипте засноване на {\lat Rainbow, Lascar} и {\lat Unicorn} алатима. Код је организован према имплементацијама које су под нападом. Наиме, за сваку имплементацију (нпр. TinyAES, mbedtls, маскирани mbedtls), направљена је засебна класа која наслеђује апстрактну класу \lstinline{SideChannelTarget}. Свака од изведених класа имплементира методе за енкрипцију и има сопствена меморијска мапирања одговарајућих променљивих. 

Скрипте функционишу тако што се најпре прави објекат класе уређаја под нападом. Такође, дефинишу се битне променљиве везане за имплементацију. Алат раинбоу омогућава качење, односно хуковање. 

Опис функција детаљно у апстрактној

Опис алата за дисасемблирање

Пример анализе над неком метом

Овако организован код омогућава лако проширење напада на друге имплементације. У случају да је потребно напасти неку другачију имплементацију, довољно је написати нову класу која имплементира интерфејс класе \lstinline{SideChannelTarget}.
 

Треба напоменути да се извршни код и меморијско мапирање може разликовати у зависности од платформе за коју се код компајлира, конфигурације компајлера и линкера итд. С тим у виду, потребно је ручно анализирати генерисану извршну датотеку. У овом раду, фокус је био на ARM архитектуре и стога је коришћен алат за декомпилацију, {\lat arm-none-eabi} који поседује неколицину корисних алата описаних у наставку.

\subsection{{\lat ARM} компајлерски пакет}

У оквиру овог алата налази се и декомпајлер, односно дисасемблер...

\subsection{-nm алат за листање }

\url{https://manpages.debian.org/testing/binutils-arm-none-eabi/arm-none-eabi-nm.1.en.html}

Добија се листа симбола, конкретно коришћен је на следећи начин...

\subsection{-objdump алат за дисасемблирање }

\url{https://manpages.debian.org/testing/binutils-common/objdump.1.en.html}

Изворни код скрипте за генерисање дат је на следећој адреси:

\section{{\lat Lascar} алат за обраду трагова}

Иста компанија која је развила {\lat Rainbow}, развила је и библиотеку за нападе споредним каналима, {\lat Lascar}. 

У оквиру овог рада, библиотека је коришћена за имплементацију складишта (енг. {\lat container}) трагова.

Синхронизација...

\section{{\lat ZephyrOS} оперативни систем}

{\lat ZephyrOS} је оперативни систем за рад у реалном времену (енг. {\lat Real-Time Operating System}) отвореног кода подржан од стране {\lat Linux} фондације. Један од главних адута овог система јесте одлична подршка за {\lat bluetooth} подсистем. 

\subsection{{\lat Bluetooth} упаривање}

Упаривање два уређаја је процес успостављања "поверења" између два уређаја, односно креирање и размена тајни које омогућавају сигурну комуникацију. Након што су уређаји упарени, могућа је шифрована комуникација и потврђивање идентитета без потребе за поновним проласком кроз читав процес за сваку следећу конекцију.

Током процеса упаривања, дели се неколико кључева, од којих је, на пример, за енкрипцију, најбитнији \textbf{дугорочни кључ} (енг. {\lat Long-Term Key - LTK}). За овај рад ипак је битнији \textbf{кључ за разрешење идентитета} (енг. {\lat Identity Resolving Key - IRK}). {\lat IRK} је 128-битни кључ који упареним уређајима омогућава да идентификују "саговорника" чак и у случајевима када остали уређаји немају могућност да повежу адресу којом се неки уређај оглашава и његов стварни идентитет.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{pairing.png}
    \caption{Процес упаривања два уређаја \cite{mediumBLEpairing}}
    \label{fig:ble-pairing}
\end{figure}

\subsection{{\lat Bluetooth} оглашавање}

Уређаји способни за комуникацију путем блутута, могу да користе такозвани механизам оглашавања (енг. {\lat advertising}) како би осталим блутут уређајима пријавили своје присуство. Ово је евидентно код уређаја у широкој употреби као што су паметни сатови, слушалице, периферије за рачунар и други.

Канали (опсези фреквенција) 37, 38 и 39 имају улогу искључиво преношења пакета оглашавања како се не би загушио "регуларан" саобраћај. Такође, оглашавање није константно већ се дешава у кратким интервалима, такозваним \textbf{догађајима оглашавања} (енг. {\lat advertising events}). Параметар за подешавање трајања ових интервала је кориснички дефинисан и краћи интервал омогућава брже откривање, уз већу потрошњу енергије и обратно. 

Пакет (енг. {\lat Protocol Data Unit - PDU} који се шаље у току оглашавања има следећу структуру:

%TODO: describe PDU

Један од битних концепата за овај рад јесте адреса уређаја који се оглашава. Свака адреса је дужине 48 бита. На слици \ref{fig:rpa-address} испод приказани су могући типови адреса које уређај може имати. 

\textbf{Јавна адреса (енг. {\lat Public})}

Ово је адреса коју произвођач уређаја програмира. Статична је током читавог животног века уређаја. Овај тип адресе надзире интернационално тело за сертификацију {\lat IEEE}, и издавање исте прати и плаћање накнаде. Издавање јавних адреса врши се на сличан начин као што је то случај са {\lat MAC} адресама, те се понекад овај тип адресе назива {\lat bluetooth MAC}.

\textbf{Насумична адреса (енг. {\lat Random})}

За разлику од јавне адресе, за коришћење насумичне адресе није потребна сертификација и самим тим, цена коришћења је мања па се стога највећи број блутут уређаја идентификује управо овим типом адресирања. Насумична адреса као таква није у употреби, већ се користе њени подтипови описани у наставку.

\textbf{Насумична статична адреса (енг. {\lat Random Static})}

Овај тип адресе се може подесити од стране корисника блутут уређаја и може се променити приликом подизања система, али не и у току рада.

\textbf{Насумична приватна (енг. {\lat Random Private})}

Оно што је најзанимљивије у контексту овог рада јесу приватне адресе. Њихова намена јесте да се сакрије идентитет уређаја који је присутан на блутут мрежи и да се онемогући његово праћење. Наиме, ова класа адреса се периодично мења током рада уређаја (период се може подесити од стране корисника). У случају приватних адреса такође постоје две варијанте: разрешива (енг. {\lat Resolvable}) и неразрешива (енг. {\lat Unresolvable}) чији је опис дат испод.

\textbf{Разрешива приватна адреса (енг. {\lat Random Private Resolvable})}

Уређај који користи овај тип адресе за оглашавање жели да сакрије свој идентитет од осталих учесника мреже, осим у случају да су ти уређаји они којима верује. Наиме, да би се ова адреса разрешила, потребно је разменити тајни кључ за разрешење идентитета (енг. {\lat Identity Resolving Key, IRK} приликом успостављања конекције. Овај кључ користе обе стране конекције, где оглашавач генерише своју адресу помоћу кључа, а уређај који слуша разрешује ту исту адресу. Иза ове адресе крије се стварна адреса уређаја која је и даље јавна или насумична статична адреса. Дакле, сигурност овог типа комуникације у потпуности се ослања на тајност {\lat IRK}-а
Ово је тип адресе који ће бити главни фокус овог рада. Интерни механизми функционисања биће поближе описани у наставку.

\textbf{Насумична неразрешива приватна (енг. {\lat Random Private Non-Resolvable})}

Овај тип адресе у потпуности онемогућава повезивање адресе са уређајем. Другим речима, не постоји начин да се адреса којом се уређај оглашава буде повезан са стварном адресом уређаја - адреса се не може разрешити. Главна улога је спречавање праћења уређаја и није у широкој употреби.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{ble_address.png}
    \caption{Типови адреса блутут уређаја}
    \label{fig:enter-label}
\end{figure}

\subsection{Генерисање разрешиве приватне адресе}

Процес генерисања {\lat RPA} адресе дефинисан је блутут стандардом и интерно користи АЕС алгоритам. Адреса се састоји из два дела:

\begin{enumerate}
    \item Насумични део (\lstinline{prand}): 24-битни насумично генерисан број
    \item Хеш део (\lstinline{hash}): 24-битни криптографски хеш
\end{enumerate}

Хеш део се генерише тако што се 128-битни блок, \lstinline{prand} допуњен нулама, енкриптује АЕС алгоритмом у {\lat ECB} начину надовезивања. Кључ који се користи приликом ове енкрипције јесте {\lat IRK}. Од резултата енкрипције узимају се 24 најзначајнија бита који се потом спајају са \lstinline{prand} делом адресе.

$$hash = \mathbf{MSB_{24}(AES_{128}(IRK, prand))}$$
$$RPA = hash ||prand$$

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{RPA.png}
    \caption{Структура {\lat RPA} адресе \cite{novelbitsBLEprivacy}}
    \label{fig:rpa-address}
\end{figure}

Уређај који уочи {\lat RPA} адресу у етру може, само уколико је упарен и самим тим има {\lat IRK}, да закључи идентитет уређаја који се том адресом оглашава. Потврда се врши такође применим АЕС алгоритма: на \lstinline{prand} део адресе примењује се енкрипција и потом се резултат проверава са оглашеним \lstinline{hash} делом адресе.

Дакле, сигурност механизма приватности у {\lat BLE} технологији директно зависи од тајности {\lat IRK} кључа. Управо стога, он ће бити мета напада у остатку рада.

\section{Опис {\lat ZephyrOS} апликације под нападом}

У циљу примене емулације на донекле реалистичан сценарио, изабрана је имплементација једноставне {\lat Bluetooth Low Energy - BLE} апликације у оквиру {\lat ZephyrOS} оперативног система. Једина сврха апликације јесте симулирање {\lat BLE} оглашавања где уређај штити свој идентитет коришћењем насумичне разрешиве адресе. Намерна једноставност апликације омогућава лакшу изолацију и прикупљање трагова за напад споредним каналима у току извршавања најкритичније операције - генерисање {\lat RPA}, али се баш из тог разлога не може сматрати као апликација спремна за продукцију.

Апликација извршава следеће кораке:

\begin{enumerate}
    \item \textbf{Иницијализација:} На почетку апликације се конфигурише и покреће {\lat bluetooth} подсистем позивом функције \lstinline{bt_enable}
    \item \textbf{Креирање идентитета}: Функција \lstinline{bt_id_create()} генерише нови {\lat bluetooth} идентитет, односно адресу. У овом кораку се подсистему прослеђује фиксан {\lat IRK}.
    \item \textbf{Подешавање оглашавања}: Креирана структура за оглашавање \lstinline{adv_params} позивом функције \lstinline{bt_le_ext_adv_create} се региструје унутар подсистема и користи се већ поменут {\lat IRK}.
    \item \textbf{Покретање оглашавања}: Позивом функције \lstinline{bt_le_ext_adv_start()} започиње се слање пакета за оглашавање. У позадини се као адреса у тим пакетима користи {\lat RPA} генерисана на основу кључа.
\end{enumerate}

%TODO: Интервал оглашавања describe

Као криптографска библиотека биће коришћен {\lat mbedtls} модул. Дефинисањем ... конфигурационих параметара ефективно се бира ... За све криптографске операције, па самим тим и генерисање {\lat IRK} кључа, биће коришћена управо ова библиотека.

Напомена је да у оквиру {\lat mbedtls} библиотеке нема гаранција за отпорност на нападе споредним каналима (који нису мерење времена) \cite{Mbed-TLS}. Наиме, то је могуће видети и из чињенице да једноставан напад корелацијом споредних канала могућ. Стога, биће имплементирано маскирање првог реда како би се отклонило цурење првог реда.

У претходним верзијама {\lat Zephyr} пројекта, за криптографске операције била је коришћена {\lat tinyAES} библиотека која такође нема имплементирану заштиту од напада споредним каналима. У овом раду неће бити подробно истраживана ова библиотека, али ће бити дат кратак показни пример за анализу извршне датотеке и генерисање трагова.

Приликом компајлирања, могуће је одабрати конфигурациони фајл који ће "прегазити" (енг. {\lat override}) подразумевану конфигурацију на следећи начин:

\begin{lstlisting}[language=bash]
west build -b qemu_cortex_m3 <app_path> --pristine \
-- -DEXTRA_CONF_FILE=masked.conf
\end{lstlisting}

На овај начин може се лако генерисати извршна датотека са или без имплементираног АЕС маскирања.

Апликација је тестирана у \lstinline{native_sim} окружењу, односно на \lstinline{Linux} оперативном систему. Приложени логови апликације показују процес креирања адресе и оглашавање:

%TODO: insert logs

Као физички уређај коришћен је {\lat bluetooth USB} наставак који подржава {\lat BLE} протокол. За верификацију самог оглашавања коришћена је мобилна апликација \lstinline{nRF Connect} која омогућава скенирање {\lat BLE} саобраћаја. Потврда да се уређај заиста оглашава коришћењем генерисане {lat RPA} адресе дата је на снимку екрана поменуте апликације:

%TODO: insert nrfConnect ss

Како би се омогућило генерисање трагова, апликација је преведена за архитектуру \lstinline{qemu\_cortex\_m3}, са могућношћу избора између маскиране и немаскиране имплементације АЕС алгоритма. Конфигурациони фајлови \lstinline{prj.conf} и \lstinline{masked.conf} садрже опције за превођење.

\subsection{АЕС функције и маскирање}

Целокупна логика коришћене верзије АЕС алгоритма налази се у оквиру \lstinline{aes.c} и \lstinline{aes.h} фајлова. На основну имплементацију, додата је и маскирана имплементација у поменутим фајловима.


Тип маскирања који је искоришћен јесте буловско маскирање првог реда. Схема је описана испод:

Како је већ напоменуто, на линеарне функције је лако применити маскирање по деловима - сваки део тајне променљиве засебно се {\lat XOR}-ује са маском. Имплементиране су функције са праволинијском применом маскирања: \lstinline{masked_shift_rows}, \lstinline{masked_shift_rows}, \lstinline{masked_mix_columns} где се осим над улазним вредностима, линеарне функције примењују и на маске. На пример, у оквиру функције смицања редова, истовремено се смичу редови стања и редови стања маске. Ове функције се потом користе у складу са АЕС спецификацијом, без измена.

С друге стране, функције \lstinline{masked_subword} и \lstinline{masked_sub_bytes} су имплементиране како би се покрили и нелинеарни случајеви. У њиховој имплементацији користи се генератор псеудослучајних бројева за генерисање излазних маски.

Како би се операција {\lat SBOX} применила над маскираним улазом $x = x_0 \oplus x_1$ и као резултат добио $y = y_0 \oplus y_1; y = SBOX(x)$ потребно је имплементирати алгоритам који не ради над немаскираним вредностима ни у једном тренутку.

У овом раду имплементиран је приступ заснован на динамичком ремаскирању табеле претраживања, односно {\lat SBOX} табеле. У обе поменуте функције примењен је исти приступ, са главном разликом у величини улаза и излаза - бајт или реч (4 бајта). \lstinline{masked_subword} примењује замену бајтова над 32-битном речи у оквиру проширивања кључа. \lstinline{masked_sub_bytes} примењује замену свих бајтова у целој матрици стања (16*16).

\begin{enumerate}
    \item Припрема улаза и генерисање нових маски: функције примају један бајт \textit{маскираног стања} (примена осталих маскираних ф-ја) - \lstinline{x_prim}, односно $x_0$ уз његову улазну маску, односно $x_1$. Након тога, генерише се насумична излазна маска \lstinline{m_out}
    \item Израчунавање привремене маскиране табеле: Прави се локална копија табеле израчунавања унапред (енг. {\lat forward lookup table}) тако што се сваки елемент оригиналне {\lat SBOX} табеле комбинује ($\oplus$) са излазном маском, \lstinline{m_out}.
    \item "Скидање маске" и замена: на \lstinline{x_prim} се примењује улазна маска, односно добија се немаскирани улаз. Ова вредност се користи за приступ динамичкој, маскираној табели: \lstinline{y_prim = T[demasked_byte]}. \lstinline{y_prim} је заправо $S(x) \oplus m_{out}$, односно први део (енг. {\lat share}) маскираног излаза
    \item Ажурирање стања: тренутно стање се поставља на добијени резултат, \lstinline{y_prim} и одговарајућа маска у матрици маски се поставља на вредност \lstinline{m_out}.
\end{enumerate}

За потврду исправности схеме маскирања искоришћен је тест у оквиру \lstinline{aes.c}. Измене су направљене у оквиру тест кода да би се кључ и текст за енкрипцију поклопио са тест векторима у FIPS стандарду \cite{FIPS-AES}. Резултати извршавања теста дати су испод:

%TODO: test execution logs

%TODO: move into the SNR section
Као други механизам провере, примењена је и {\lat SNR} анализа над генерисаним траговима.

\chapter{Модели машинског учења за напад споредним каналима}

Ово поглавље представља преглед коришћених архитектура неуронских мрежа коришћених за напад споредним каналима како на {\lat ASCAD} скупу података, тако и на синтетичком скупу података
ф\section{Архитектура - Конволутивна неуронска мрежа}

За почетну архитектуру конволутивне неуронске мреже одабрана је архитектура \textit{CNN\textsubscript{best}} представљена у раду \cite{prouff2018ascad}. Архитектура коју су аутори представили као најбољу се заснива на \textit{{\lat VGG}} \cite{simonyan2014very} типу неуронске мреже, и конкретно, има следеће карактеристике:

\textbf{Улазни слој:} Прихвата трагове дужине 700 временских тачака (ово је дужина трагова у {\lat ASCAD} скупу података).

\textbf{Конволутивни блокови:} Мрежа је сачињена од пет конволутивних једнодимензионалних слојева (\lstinline{Conv1D}) са језгром величине 11 и \textbf{{\lat ReLU}} активационом функцијом. После другог и петог конволутивног слоја, налази се \lstinline{MaxPooling1D} слој за агрегацију са величином прозора 2. Б

Сиже архитектуре дат је на слици испод:

\textit{Имплементација ове мреже дата је на следећем линку: ()[].}

\section{Архитектура - {\lat CNN + SE}}
\label{chp:cnnseimpl}

Такође, у \cite{GaoLiuAttnCNN} аутори користе хибридни модел пажње, односно СЕ блокове. Инспирација за надоградњу 

Архитектура са додатим {\lat Squeeze Excitation} слојевима надограђује описану {\lat CNN\textsubscript{best}} архитектуру додавањем {\lat SE} слоја након другог и петог конволутивног блока.

\textbf{{\lat SE} блок} је имплементиран на следећи начин:

\textbf{{\lat Squeeze}:} Користи се {\lat GlobalAveragePooling1D} како би се агрегирале карактеристике дуж просторне димензије. Овом операцијом се добија дескриптор канала.

\textbf{{\lat Excitation}:} Овим слојем се побуђују канали, односно добијају се оцене значаја сваког канала. Наведено се постиже прослеђивањем дескриптора канала кроз два потпуно повезана слоја ({\lat Dense}). Први слој смањује димензионалност за одређену величину \lstinline{se_ratio} и има {\lat ReLU} активациону функцију. Следећи слој реконструише оригиналну димензионалност и помоћу сигмоидне функције додељује тежине сваком од слојева. На крају, оригинални тензор се множи добијеним тежинама канала, на тај начин појачавајући утицај значајнијих а смањујући утицај мање значајних канала.

\section{Архитектура - {\lat CNN + CBAM}}

Следећа конволутивна архитектура која је испитана је надоградња {\lat CNN\textsubscript{best}} мреже конволутивним блок модулом пажње (енг. {\lat Convolutional Block Attention Module}). Слој је имплементиран тако да секвенцијално примењује пажњу на канале, а затим на просторне димензије. Уметање {\lat CBAM} слојева извршено је, као и код {\lat SE} варијанте, пре операције смањивања димензионалности. У овој архитектури, коришћени су \lstinline{AveragePooling1D} слојеви како би се очувало више информација о локацији цурења. {\lat CBAM} блок састоји се из две компоненте:

\begin{enumerate}
    \item Модул пажње канала (енг. {\lat Channel Attention Module})
    \item Модул просторне пажње (енг. {\lat Spatial Attention Module})
\end{enumerate}

\section{Архитектура - гаусовска пажња}

Инспирација за ову архитектуру потекла је из радова \cite{hajra2022transnet} и \cite{hajra2024estranet}. Наиме, аутори наведених радова, примењују главне идеје из рада \cite{vaswani2017attention}, односно механизам пажње. У {\lat TransNet} архитектури, блиско се прати архитектура трансформера из рада Васванија и других те се механизам пажње моделује многоглавом самопажњом. ...
Овако конструисана мрежа и даље има квадратну сложеност тренинга, управо јер се свака тачка улазног трага проверава .. У свом наредном раду, Хајра и други уводе гаусовски модел пажње који време тренинга смањује на линеарно. Идеја је да се уместо моделирања потпуне корелације свих тачака трага моделују оне тачке које су блиске једне другима темпорално јер се на основу домена проблема претпоставља јача повезаност блиских тачака. Ово је такође разлог због чега су и конволутивне мреже имале успеха у области напада споредним каналима.

Конкретно, модел имплементиран у овом раду има следећу структуру: полазећи од саме главе пажње, уводе се параметри које мрежа може научити.

Иницијализација:

С обзиром да је {\lat ASCAD} скуп података јавно доступан и веома истражен у домену споредних канала, познате су и тачке цурења (ово важи и за друге скупове података где се знају маске, уколико оне постоје). 

Центри гаусовских звона бирају се насумично из униформне расподеле, док се ширина фиксира на 30. Овај параметар је одабран случајно и није био део претраге хиперпараметара. Свакако је мрежи остављена могућност учења и модификације ових параметара.

Следеће конструисан је слој неуронске мреже {\lat GaussianTransformerBlock} чије инстанце је могуће слагати једне на друге. 

Иако аутори рада користе такозвани слој центрирања {енг. \lat LayerCentering}, у раду није стављен фокус на имплементацију овог слоја, и за нормализацију се ослањало на глобално упросечавања ()

\section{Тренинг}

Користећи терминологију напада споредним каналима, тренинг се поистовећује са профилисањем, док се евалуација поистовећује са нападом. {\lat ASCAD} скуп података садржи ове податке под именом ... Конкретно, коришћен је {\lat Keras Tuner} објекат који  У наставку биће описани параметри над којима је вршена претрага.

\subsection{Архитектура {\lat CNN}}

За конволутивну неуронску мрежу претрага хиперпараметара

Претрагра хиперпараметара. Чување модела. Метрике евалуације - недостаци вал лосса. Спорадична евалуација ранга кључа.

\subsection{Аблациони експерименти (нормализација бачве искде)}


\section{Евалуација (напад)}

Сам напад, односно у контексту машинског учења тестирање, спроводи се над једним бајтом кључа. За откривање потпуног кључа користи се такозвана стратегија "подели па владај" (енг. {\lat Divide and Conquer}, односно тренира се $N$ модела где је $N$ број бајтова кључа (у случају АЕС 128 варијанте $N$ je 16). Скуп података који је предвиђен за ову етапу најчешће се у литератури назива скупом за напад (енг. {\lat Attack}), и у {\lat ASCAD} скупу података доступан је ... За саму оцену квалитета модела, нису довољне класичне метрике попут прецизности. Ово произилази из чињенице да се напад не спроводи у оквиру једног проласка кроз улазне податке, већ се резултати предвиђања сабирају и модел заправо служи као ансамбл модела. 

\subsection{Ранг кључа}

Као што је споменуто, напади споредним каналима се ослањају на стратегију поделе на поделементе кључа које је лакше напасти. Даље, сваки модел се евалуира у односу на успешност предвиђања истинског кључа. Конкретно, за сваког кандидата за бајт кључа рачуна се скор и кандидати се ређају се од најбољег ка најлошијем.

\begin{algorithm}
\caption{Напад споредним каналима}\label{alg:cap}
\begin{algorithmic}[1]
    \Statex \textbf{Input:} Функција за оцену напада $f(\cdot)$
    \Statex \textbf{Input:} Кандидати кључа $\mathcal{K}$ величине $|\mathcal{K}|$
    \Statex \textbf{Data:} Трагови споредних канала (симулирани или измерени)
    \Statex \textbf{Output:} $score_k, guess_k, rank_k$, за све $k \in \mathcal{K}$ и све партиције кључа
    \State
    \State Подели пун кључ и нападни сваку партицију
    \State $partitions \gets \text{divide-and-conquer}(\text{fullkey})$
    \ForAll{all partitions}
        \State Израчунај оцену напада за сваког кандидата кључа
        \ForAll{all $k \in \mathcal{K}$}
            \State $score_k \gets f(\text{traces}, k)$
        \EndFor
        \State
        \State Сортирај оцене и израчунај погађања кључа
        \State $[score_i, score_j, \dots, score_m] \gets \text{sort}([score_0, score_1, \dots, score_{|\mathcal{K}|-1}])$
        \State $[guess_1, guess_2, \dots, guess_{|\mathcal{K}|}] \gets [i, j, \dots, m]$
        \State
        \State Израчунај ранг сваког кандидата кључа користећи погађања
        \ForAll{all $guess_i$, $i \in \{1, 2, \dots, |\mathcal{K}|\}$}
            \State $rank_{guess_i} \gets i$
        \EndFor
    \EndFor
\end{algorithmic}
\end{algorithm}

Алгоритам преузет из \cite{papagiannopoulos2023side}

(1) С обзиром да се нападају вредности од 8 бита, постоји 256 могућности за кандидате кључа $k$, односно $K = {0,1,...,255}$.

(2) Напад на 8-битне вредности производи 256 оцена $[score_0, score_1, ...,score_255]$ где је $score_k$ оцена кандидата кључа $k$ приликом напада.

(3) На основу израчунатих оцена, алгоритам бира најбоље кандидате, односно конструише се листа $[guess_1, guess_2, ...,guess_255]$. Први елемент ове листе јесте онај кандидат кључа који је постигао најбољу оцену у претходном кораку и самим тим представља кандидата за који је модел најсигурнији. 

(4) На крају, прави се листа рангова кандидата кључа $[rank_0, rank_1,...,rank_255]$ где је $rank_k$ ранг кандидата кључа $k$. Другим речима, уколико је у претходним корацима закључено да је, на пример, $k_{13}$ имао најбољу оцену, и самим тим $guess_1 = 13$, ранг тог кандидата једнак је нули, односно највероватнијем бајту кључа. Интуитивно, пожељно је да у сортираном низу рангова, на првом месту буде кандидат кључа који се поклапа са стварним кључем. Под претпоставком да је познат тајни кључ у фази напада (претпоставка којом се воде експерименти у оквиру рада), рачуна се удаљеност кандидата кључа који је постигао ранг 0 и стварног бајта кључа.

Такође може бити корисно графички представити такозвану еволуцију ранга кључа. Требало би видети стрм пад ранга који опстаје у истом региону са повећањем трагова што указује на конвергенцију и успешан напад.

\subsubsection{Имплементација}

У овом одељку биће описан приступ имплементацији ранга кључа конретно у овом раду.

Функција \lstinline{rank} имплементира рачунање метрике ранга за један бајт кључа. За дати скуп предвиђања модела (вероватноћа за сваку од 256 могућих класа) и одговарајуће метаподатке (тачан бајт кључа и бајт отвореног текста) рачуна се оцена итеративним путем. Опис функције дат је испод:

\begin{enumerate}
    \item \textbf{Иницијализација:} Креира се низ \lstinline{key_bytes_proba} дужине 256, иницијализован нулама. Сваки елемент овог низа ће акумулирати оцене (скор) кандидата кључа тако што ће елемент $proba_i$ садржати акумулиран скор за кандидат кључа $ k=i $.
    \item \textbf{Акумулација скора:} За сваки траг коришћен у нападу, функција пролази кроз 256 могућих кандидата кључа и ради следеће
    \begin{itemize}
        \item На основу отвореног текста (\lstinline{plaintext}), и кандидата кључа (\lstinline{key_guess}) рачуна се осетљива међувредност $SBOX(p_i \oplus k_i)$. Ово је заправо оно што модел покушава да предвиди.
        \item На основу вектора предвиђања модела за дати траг, и вредности израчунате у претходном кораку, извлачи се одговарајућа вероватноћа: \lstinline{proba = predictions[trace_idx][SBOX[plaintext ^ key_guess]]}.
        \item Израчуната вероватноћа додаје се вектору \lstinline{key_bytes_proba}. Због нумеричке стабилности, додаје се логаритам вероватноће из претходног корака.
    \end{itemize}
    \item \textbf{Израчунавање ранга:} Након обраде свих трагова, низ \lstinline{key_bytes_proba} садржи коначне оцене за све кандидате. Сортирањем овог низа проналази се позиција (у овом контексту ранг) скора која одговара стварном кључу.
\end{enumerate}

На аттацк скупу тек, Дивиде анд цонкуер тј. 16 модела. Ранг кључа .. гуессинг ентропија исто спомен.

% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\chapter{Резултати и анализа}
% ------------------------------------------------------------------------------

\section{Анализа цурења помоћу {\lat SNR}-а}

Овај одељак приказује резултате анализе {\lat SNR} величине за сваки од коришћених скупова података.

\subsection{{\lat ASCAD} скуп података}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{ascad-traces.png}
    \caption{Прва 4 трага {\lat ASCAD} скупа података}
    \label{fig:ascad-traces}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{ascad-snr.png}
    \caption{{\lat SNR} анализа {\lat ASCAD} скупа података}
    \label{fig:ascad-snr}
\end{figure}

Очигледно је да не постоји цурење првог реда, односно да је схема маскирања у потпуности отклонила везу потрошње енергије и осетљивих променљивих. С друге стране, цурење другог реда и даље је присутно што се може видети на слици \ref{fig:ascad-snr-second-order}. Наиме, уколико су познате маске коришћене током извршавања алгоритма, могуће је пратити цурење другог степена. Нападач свакако нема приступ овим "огољеним" траговима, али постојање другог степена цурења отвара могућност за нападе вишег степена и то конкретно, нападе уз помоћ модела машинског учења.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{ascad-snr-second-order.png}
    \caption{{\lat SNR} анализа {\lat ASCAD} скупа података са познатим маскама}
    \label{fig:ascad-snr-second-order}
\end{figure}

\subsection{Скупови података генерисани {\lat Rainbow} библиотеком}

\subsubsection{{\lat tinyAES} скуп података}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{tinyAES-traces.png}
    \caption{Првих 5 трагова {\lat tinyAES} извршавања}
    \label{fig:tinyaes-traces}
\end{figure}

У овом одељку биће приказани вештачки генерисани трагови над \lstinline{tinyAES} имплементацијом. На слици \ref{fig:tinyaes-traces} види се првих 5 трагова извршавања овог алгоритма. Оно што је на први поглед очигледно јесте постојање 10 карактеристичних региона на графику. Ово би требало да одговара 10 рунди \lat{AES} алгоритма.

Слика \ref{fig:tinyaes-snr} приказује однос сигнала и шума. У региону између тачке 500 и тачке 1000, уочава се јасно испупчење на графику. Ово је индикација да је цурење у том региону јако и да се баш ту налазе тачке интереса. Ово ће касније бити потврђено и успешним {\lat CPA} нападом, који без проблема извлачи кључ из овог немаскираног трага.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{tinyAES-SNR.png}
    \caption{{\lat SNR} анализа {\lat tinyAES} трагова}
    \label{fig:tinyaes-snr}
\end{figure}

\subsubsection{{\lat mbedtls} скуп података - без маскирања}

Трагови немаскиране ... имплементације дати су на 

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{mbedtls-traces.png}
    \caption{Првих 10 трагова немаскиране {\lat mbedtls} имплементације}
    \label{fig:mbedtls-traces}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{mbedtls-snr.png}
    \caption{{\lat SNR} анализа немаскиране имплементације}
    \label{fig:mbedtls-snr}
\end{figure}

Као и код претходно анализираних трагова, испупчења су јасно видљива...

\subsubsection{{\lat mbedtls} скуп података - са маскирањем}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{mbedtls-masked-traces.png}
    \caption{Први траг {\lat mbedtls} скупа података}
    \label{fig:mbedtls-masked-traces}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{mbedtls-masked-snr.png}
    \caption{{\lat SNR} анализа {\lat mbedtls} скупа са маскирањем првог степена}
    \label{fig:mbedtls-masked-snr}
\end{figure}

Овде већ трагови и анализа делују занимљивије - испупчења су равномерније распоређена. Не толико добро као аскад - могућ разлог у симулацији и јос додатно што је софтверска имплементација


\subsection{Трансформер}

Од објављивања (атнппр), 

Резултати модела, поређење.. МЛ део приче

Импликације на аскаду, импликације на синтетичком трејсу.

Практични део приче - симулација напада. Деанонимизација бт корисника 

% ------------------------------------------------------------------------------
\chapter{Закључак}
% ------------------------------------------------------------------------------




% ------------------------------------------------------------------------------
% Literatura
% ------------------------------------------------------------------------------
\literatura

% ==============================================================================
% Završni deo teze i prilozi
\backmatter
% ==============================================================================

% ------------------------------------------------------------------------------
% Biografija kandidata
\begin{biografija}
\textbf{Александар Врачаревић} (\emph{Београд, 10. фебруар
  1996.}) завршио је XIII београдску гимназију 2014. Наредне године уписује математички факултет универзитета у београду. Након завршених студија започиње праксу у области имплементације компајлера. Следеће радно искуство подразумевало је рад са графичким картицама и конкретно, имплементацијом и тестирањем безбедносних компоненти графичких картица. Следећи пројекат подразумевао је развој сигурног система комуникације између {\lat STM32} микроконтролера помоћу криптографског ацелератора. Након тога, започиње развој уградног софтвера у аутомобилској индустрији, са фокусом на сигурност. На мастер студијама фокус му је углавном био на криптографији и машинском учењу.
\end{biografija}
% ------------------------------------------------------------------------------

\end{document} 